% LaTeX file for Chapter 04


\chapter{Discussion and Outlook}


Check all of the following again when including the final Experiment results in section 3 (here written just from memory):


\section{Experiment 1: TRAM-DAG simulation}

The tram dag can accurately estimate the causal dependencies with interpretable coefficients.


\section{Experiment 2: ITE estimation - IST stroke trial}

We used the same data as was used by \ref{chen2025}. Both models, the tuned RF and the TRAM-DAG did not generalize to the test set. The results are very similar to the ones of the original paper. Calibration seemed to be not bad in both cases...Possible reasons could be small true heterogeneity, low effect size of the treatment, missing important variables (e.g. effect modifiers/interaction variables with treatment). In the the next section (discussion for experiment 3) we are looking into those cases in a simulation study.


\section{Experiment 3: When do causal ML models fail? (ITE simulation study)}

All models achieve good performance as long as the effect sizes are large and the dag is fully observed. Once effect sizes and through that heterogeneity gets smaller, the models become powerful (which is obvious since we can not estimate an effect where there isnt an effect in reality). But in the training sets the complex models still estimate a quite high ITE but this doesnt generalize to the test sets. The largest problem occured when an effect modifier (interaction variable was unobserved), meaning that it was included in the data generating mechanism but not included in the dataset for training the models. 



\section{Experiment 4: TRAM-DAGs in Observational vs. RCT setting  (ITE simulation study)}

We analyzed ITE estimation under an observational setting (confounded) and under an RCT setting (randomized treatment allocation) in three different scenarios - direct and interaciton treatment effect, only direct but no interaction effect, and no direct but with interaction effect. We noticed that in the first scenario with 


What might be surprising is that in scenario 1 where we dont have explicitly included interaction terms in the data generating process, there is still some heterogeneity in the treatment effect (as shown in figure XX). One might expect that the ITE is constant across all individuals in such a case. However since we used a non linear transformatino function as intercept in the data generating process (as would likely be the case in a real world setting), the treatment effect is not constant across all individuals (that is the ATE). When a linear transformation function would be applied (as for example a linear regression is specified, where the latent noise distribution would be the standard normal and the transformation function would be linear) then the noise term cancels out when calculating the ITE, leading to a constant ITE when no interactions are present: $\text{ITE} = \text{E}[Y(1)] -\text{E}[Y(0)] = (\beta_0 + \beta_t 1 + \beta_x X + \epsilon) - (\beta_0 + \beta_t 0 + \beta_x X + \epsilon) = \beta_t$.

In a model with nonlinear transformation, as in this experiment, the noise term does not cancel out anymore leading to different ITEs for patients with different characteristics.

\begin{equation}
\text{ITE} = \text{E}[Y(1) - Y(0)] = \text{E}[h^{-1}(Z + \beta_t 1 + \beta_x X)] - \text{E}[h^{-1}(Z + \beta_t 0 + \beta_x X)] 
\end{equation}

where $h$ is the nonlinear transformation function, $Z$ is the latent noise term, $\beta_t$ is the direct treatment effect and $\beta_x$ are the coefficients of the covariates. The state of the covariates $X$ alters the position on the transformation function and thereby affects the difference between the two terms. If the transformation was fixed to be linear, the difference would be constant independent of the state of the covariates $X$. (This also has to do with non-collapsibility as discussed by susanne and torsten , also check Beates Mail 21.06.2025, and chatgpt discussion)

% cite susanne and torsten paper: https://arxiv.org/abs/2503.01657
