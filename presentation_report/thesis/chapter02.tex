

% LaTeX file for Chapter 02


\chapter{Methods} 

In this section I will explain the necessary background needed to understand the TRAM-DAGs. Once the framework of tram dags is explained, I will present how the experiments of the simulation, the application on real data and the ITE estimation are conducted. Following research questions are addressed:

\begin{itemize}

\item How can TRAM-DAGs be applied under different scenarios (datatypes, DAG structure, complexity, scaled varaibles) and how does this influence the interpretation of parameters?
\item Why does the estimation of Individualized Treatment Effects (ITE) fail in some cases for most causal ML methods when validating them out of sample? 
\item How can TRAM-DAGs be used to estimate the Individualized Treatment Effect (ITE) in a RCT and in a observational setting with confounding and mediating variables?

\end{itemize}

\section{TRAM-DAGs}

The goal of TRAM-DAGs is to estimate the structural equations according to the causal order in a given DAG in a flexible and possibly still interpretable way in order to sample observational and interventional distributions and to make counterfactual statements. The estimation requires data and a DAG that describes the causal structure. It must be assumed that there are no hidden confounders. TRAM-DAGs estimate for each variable $X_i$ a transformation function $Z_i = h_i(X_i \mid pa(X_i))$, where $Z_i$ is the noise value and $pa(X_i)$ are the causal parents of $X_i$. The important part here is that we can rearrange this equation to $X_i = h_i^{-1}(Z_i \mid pa(x_i))$ to get to the structural equation. The transformation functions $h$ are monotonically increasing functions that are a representation of the conditional distribution of $X_i$ on a latent scale. They are based on the idea of transformation models as introduced by \citet{hothorn2014} but were extended to deep trams by \citet{sick2020}. In the following sections I review the most important ideas of these methods as they are the essential components of TRAM-DAGs.

\section{Transformation Models}


Transformation models are a flexible distributional regression method for various data types. They can be for example specified as ordinary linear regression, logistic regression or proportional odds logistic regression. But Transformation models further allow to model conditional outcome distributions that do not even need to belong to a known distribution family of distributions by model it in parts flexibly. This reduces the strength of the assumptions that have to be made.

The basic form of transformation models can be described by

\begin{equation}
F(y|\mathbf{x}) = F_Z(h(y \mid \mathbf{x})) =  F_Z(h_I(y) - \mathbf{x}^\top \boldsymbol{\beta})
\label{eq:transformation_model}
\end{equation}

, where $F(y|\mathbf{x})$ is the conditional cumulative distribution function of the outcome variable $Y$ given the predictors $\mathbf{x}$. $h(y \mid \mathbf{x})$ is a transformation function that maps the outcome variable $y$ onto the latent scale of $Z$. $F_Z$ is the cumulative distribution function of a latent variable $Z$, the so-called inverse-link function that maps $h(y \mid \mathbf{x})$ to probabilities. In this basic version, the transformation function can be split into an intercept part $h_I(y)$ and a linear shift part $\mathbf{x}^\top \boldsymbol{\beta}$, where the vector $\mathbf{x}$ are the predictors and $\boldsymbol{\beta}$ are the corresponding coefficients.

If the latent distribution $Z$ is chosen to be the standard logistic distribution, then the coefficient $\beta_i$ can be interpreted as log-odds ratios when increasing the predictor $x_i$ by one unit, holding all other predictors unchanged. This means that an increase of one unit in the predictor $x_i$ leads to an increase of the log-odds of the outcome $Y$ by $\boldsymbol{\beta}$. The additive shift of the transformation function means a linear shift on the latent scale (herer log-odds). The following transformation to probabilities by $F_Z$ potentially leads to a non-linear change in the conditional outcome distribution on the original scale. This means not only is the distribution shifted, also its shape can change to some degree based on the covariates. More details about the choice of the latent distribution and the interpretation of the coefficients are provided in the appendix XXX.


For a continuous outcome $Y$ the intercept $h_I$ is represented by a bernstein polynomial, which is a flexible and monotonically increasing function

\begin{equation}
h_I(y) = \frac{1}{M + 1} \sum_{k=0}^{M} \vartheta_k \, \text{B}_{k, M}(y)
\end{equation}

, where $\vartheta_k$ are the coefficients of the bernstein polynomial and $\text{B}_{k, M}(y)$ are the Bernstein basis polynomials. More details about the technical implementation of the bernstein polynomial in the context of TRAM-DAGs is given in the appendix XXX.

For a discrete outcome $Y$ the intercept $h_I$ is represented by cut-points, which are the thresholds that separate the different levels of the outcome. For example, for a binary outcome $Y$ there is one cut-point and for an ordinal outcome with $K$ levels there are $K-1$ cut-points. The transformation model is given by

\begin{equation}
P(Y \leq y_k \mid \mathbf{X} = \mathbf{x}) = F_Z(\vartheta_k + \mathbf{x}^\top \boldsymbol{\beta}), \quad k = 1, 2, \ldots, K - 1
\end{equation}


A visual representation for a continuous and discrete (ordinal) outcome is provided in Figure~\ref{fig:tram_cont_ord}.


% include image /img/tram_cont_ord.png
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{img/tram_cont_ord.png}
\caption{\textbf{Left:} Example of a transformation model for a continuous outcome $Y$ with a smooth transformation function. \textbf{Right:} Example of a transformation model for an ordinal outcome $Y$ with 5 levels. The transformation function consists of cut-points that separate the probabilities for the levels of the outcome.
In both cases the latent distribution $Z$ is the standard logistic and the predictors $\mathbf{x}$ induce a linear (vertical) shift of the transformation function.}
\label{fig:tram_cont_ord}
\end{figure}


To estimate the parameters $\boldsymbol{\beta}$ and $\boldsymbol{\vartheta}$ the negative log likelihood (NLL) is minimized. The NLL is defined as

\begin{equation}
\text{NLL} = - \frac{1}{n} \sum_{i=1}^{n} l_i(\boldsymbol{\beta}, \boldsymbol{\vartheta} ) = - \frac{1}{n} \sum_{i=1}^{n} \log (f_{Y \mid \mathbf{X} = \mathbf{x}}(y_i))
\label{eq:nll_tram}
\end{equation}

where $l_i(\boldsymbol{\beta}, \boldsymbol{\vartheta})$ is the log-likelihood of the $i$-th observation,  $l_i(\boldsymbol{\beta}, \boldsymbol{\vartheta}) = f_{Y \mid \mathbf{X} = \mathbf{x}}(y_i)$ is the conditional density function of the outcome variable $Y$ given the predictors $\mathbf{x}$ under the current parameterization. I provide the full derivation in the appendix xxx.


For the remainder of this thesis, I rely on the idea of these transformation models to model the conditional distribution functions represented by the transformation functions of the respective variables. The standard logistic distribution is used as $F_Z$, which results in a logistic transformation model.


\section{Deep TRAMs} \label{sec:deep_trams}

The transformation models as discussed before were extended to deep TRAMs using a modular neural network \citep{sick2020}. The goal is to get a parametrized transformation function of the form \ref{eq:deep_tram.}.Each part, the intercept $h_I(X_i)$, the linear shift $\mathbf{x}_L^\top \boldsymbol{\beta}_L$ and the complex shift $f_C(\mathbf{x}_C)$ are assembled by the outputs of the individual neural networks. The user can specify the level of complexity the parents $pa(X_i)$ have on the transformaiton funciton. Figure \ref{fig:deep_tram} illustrates the case for a SI-LS-CS model.

\begin{equation}
h(y \mid \mathbf{x}_L, \mathbf{x}_C ) = h_I(y) + \mathbf{x}_L^\top \boldsymbol{\beta}_L + f_C(\mathbf{x}_C)
\label{eq:deep_tram}
\end{equation}



\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{img/deep_tram.png}
\caption{Modular deep transformation model. The transformation function $h(y \mid \mathbf{x})$ is constructed by the outputs of three neural networks.}
\label{fig:deep_tram}
\end{figure}

\textbf{Intercept } the shape of the transformation function at the baseline configuration $\mathbf{x}_L^\top \boldsymbol{\beta}_L = 0$ and $f_C(\mathbf{x}_C)=0$ is determined by the intercept $h_I(y)$. For a continuous outcome the intercept is represented by a smooth bernstein polynomial and in the discrete case by cut-points. In either case the parameters $\vartheta$ are obtained as output nodes of the neural network. A simple intercept (SI) is the case where the parameters $\vartheta$ do not depend on the any explanatory variables. The neural network thereby only takes a constant as input and directly outputs the parameters $\vartheta$. To make the intercept more flexible, the intercept can also depend on the explanatory variables. In this case the complex intercept (CI) models the intercept $\vartheta(x)$ by taking the predictors $x$ as input to a neural network with some hidden layers. This allows the intercept to change with the value of the predictors. Depending on the assumptions, predictors can be used in the complex intercept, or only a subset of them. A detailed explanation of the construction of the bernstein polynomial is given in appendix XXX.

\textbf{Linear shift } If the predictors should have a linear effect on the transformation function, it can be modelled by a linear shift (LS). For this part the neural network without hidden layers and without biases takes the linear predictors $pa(X_i)$ as input and generates a single output node with a linear activation function. This results in the linear combination $\mathbf{x}_L^\top \boldsymbol{\beta}_L$ and it induces a linear vertical shift of the transformation function. The weights $\boldsymbol{\beta}_L$ are the interpretable coefficients of the linear shift. For the logistic transformation model, they are interpreted as log-odds-ratios.
The interpretation is further described in the appendix \ref{sec:interpretation_linear_coefficients}. %  for interpretation see pearl book 2009 p. 366. the key is to say leaving all other variables "untouched" and not "constant". he also talks about the connection to the do-operator.

\textbf{Complex shift } If the transformation function should be allowed to be shifted vertically in a non-linear manner, a complex shift (CS) can be applied. The predictor variables are inputted in a (deep) neural network with at least one hidden layer and non-linear activation functions such as sigmoid or ReLU. A single output node with $f_C(X_C)$ is obtained. With a complex shift, also interactions between predictor variables can be captured by giving the interacting variables into the same neural network.


\textbf{Level of complexity } One practical feature of these modular deep TRAMs is that one can specify, which predictors should have a linear or complex shift effect on the transformation function or that predictors are even allowed to deterimine the shape of the transformation function by a complex intercept. \citet{herzog2023} predicted the ordinal functional outcome three months after stroke by using semi-structured data that included tabular predictors and images. The two data modalities can be included in a single deep TRAM by modeling the part of the images with a CNN.

The estimated distribution function is invariant with respect to the choice of the inverse-link function $F_Z$ (scale of latent distribution) in an unconditional \citep{hothorn2018} or fully flexible (CI) setting. However, as soon as restrictions are placed on the influence of the predictors (LS, CS), this leads to assumptions about the scale of the dependency. Which latent distribution should be chosen depends on following factors: (i) the intended complexity of the model, (ii) the assumptions about the data generating process, (iii) the conventional, widely used, scale of interpretation for the specific problem. If the coefficients $\beta$ in the linear shift term should be interpreted as log odds ratios, then the standard logistic distribution is appropriate. For log hazard ratios it would be the minimum extreme value distribution. There exist plenty of other alternatives.

(The optimal scale could be found by comparing the likelihoods of the model under different latent distributions. )



\textbf{Parameter estimation } The parameters of the neural networks are learned by  minimizing the negative log-likelihood (NLL) of the conditional deep TRAM. The learning process is started with a random parameter configuration and the outputs of the neural networks are used to assemble the NLL of the transformation model. The NLL is then iteratively minimized by adjusting the parameters by the Adam optimizer \citep{kingma2015} until they eventually converge to the optimum state. Additionally, methods to prevent overfitting --- such as dropout, early stopping, or batch normalization --- can be applied. These techniques are particularly important in more complex networks to ensure that the model generalizes well to out-of-sample data. In the hidden layers, non-linear activation functions such as ReLU or sigmoid are applied.




\section{TRAM-DAGs}



In TRAM-DAGs these deep transformation models are applied in a causal setting. We assume a pre-specified DAG which defines the causal dependence. Then we estimate the distribution of each node by a transformation model that is conditional on its parents. Figrue \ref{fig:tram_dag} illustrates the basic idea of a TRAM-DAG where a DAG with 3 variables, without hidden confounder, is assumed to be known. The arrows in the DAG indicate the causal dependencies between the variables. The transformation models are constructed by a modular neural network. The assumed influence from the parent variables has to be specified as SI, LS or CS. In this example, $X_1$ is a continuous source node that acts as parent of $X_2$ and $X_3$. For a source node the transformation function only consists of a simple intercept (SI). $X_2$ is also continuous and its transformation function can be shifted additively (LS) by the value of $X_1$. $X_3$ is an ordinal variable with 4 levels and its transformation function depends on the values of $X_1$ (LS) and $X_2$ (CS). The cut-points $h(x_3 \mid x_1, x_2)$ represent the cumulative probabilities on the log-odds scale of the first 3 levels of $X_3$, where the probability of the last level $K=4$ is the complement of the previous levels $k_{1-3}$.

% include image /img/tram_dag.png
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{img/tram_dag.png}
\caption{Example of a TRAM-DAG with three variables $X_1$, $X_2$ and $X_3$. The transformation functions are represented by the modular neural networks. The arrows indicate the causal dependencies between the variables.}
\label{fig:tram_dag}
\end{figure}

This DAG with the assumed dependencies can be described by an adjacency matrix \ref{eq:MA}, where the rows indicate the source and the columns the target of the effect: 


\begin{equation}
\mathbf{MA} =
\begin{bmatrix}
  0 & \text{LS} & \text{LS} \\
  0 & 0  & \text{CS} \\
  0 & 0  & 0
\end{bmatrix}
\label{eq:MA}
\end{equation}

To apply the framework of TRAM-DAGs on this example, we assume to have observational data that follows the structure of the adjacency matrix \ref{eq:MA}. In practice, the DAG is either defined by expert knowledge or by some sort of structure finding algorithm (XXX cite methods). Then we want to estimate the conditional distribution function of each variable by a deep TRAM so that we can sample from the distributions and make causal queries. The conditional distribution functions are given by


\[
\begin{aligned}
X_1 &\sim F_Z(h_I(x_1)) \\
X_2 &\sim F_Z(h_I(x_2) + \mathrm{LS}_{x_1}) \\
X_3 &\sim F_Z(h_I(x_3) + \mathrm{LS}_{x_1} + \mathrm{CS}_{x_2})
\end{aligned}
\]


\textbf{Construct Modular Neural network}

As discussed in the section \ref{sec:deep_trams}, the transformation functions are constructed by a modular neural network. The inputs are the variables in the system as well as the adjacency matrix \ref{eq:MA} which controls the information flow and assures that only valid connections according to the causal dependence are made. Discrete variables with few categories are dummy encoded, and continuous variables should be scaled before feeding them in the neural network. The encoding and the effect of scaling on the interpretation of parameters is discussed in the appendix (\ref{sec:encoding_discrete_variables} and  \ref{sec:scaling_continuous_variables}). Scaling the input variables, meaning to bring the variables onto a zero-mean and one-variance, can remove the pattern in marginal variance which some structure learning algorithms rely on \citep{reisach2021}. However, since our analysis does not require to find the structure and already assumes a known DAG, this is not a problem. 
Once the input variables are prepared and the structure is defined by the adjacency matrix, the architecture of the neural network for the complex shift and complex intercept has to be specified. These are factors such as depth, width, activation function, and whether dropout or batch normalization should be used. These considerations depend on the assumed complexity of the shifts. The outputs of the neural networks are the three components for the transformation function (SI, LS, CS) for each variable. These components are assembled to the transformation functions. Finally, the loss is defined as the negative log likelihood, which the model aims to optimize to estimate the optimal parameterization. The estimated parameters $\boldsymbol{beta}$ in the linear shifts are interpretable as log-odds-ratios when changing the value of the respective parent by one unit, leaving all others unchanged. 




\subsection{Sampling from TRAM-DAGs}

\textbf{Observational sampling} Once the TRAM-DAG is fitted on data, it can be used to sample from the observational or interventional distribution or to make counterfactual queries. 
The structural equations $X_i = f(Z_i, \text{pa}(X_i))$ are represented by the inverse of the conditional transformation functions $h^{-1}(Z_i \mid \text{pa}(X_i))$ because $Z_i = h(X_i \mid \text{pa}(X_i))$. The sampling process from the observational distribution for one iteration (one observation of all variables in the DAG) is described in the pseudocode \ref{alg:sampling} and illustrated in Figure~\ref{fig:sampling}. The process is repeated for the desired number of samples. 

\begin{algorithm}
\caption{Generate a samples from the TRAM-DAG}
\label{alg:sampling}
\begin{algorithmic}[1]
\State \textbf{Given:} A fitted TRAM-DAG with structural equations $X_i = f(Z_i, \text{pa}(X_i))$, where $Z_i = h(X_i \mid \text{pa}(X_i))$
\For{each node $X_i$ in topological order}
  \State Sample latent value $z_i \sim F_{Z_i}$ \Comment{e.g., \texttt{rlogis()} in R}
  \If{$X_i$ is continuous}
    \State Compute $x_i = h^{-1}(z_i \mid \text{pa}(x_i))$ by solving $h(x_i \mid \text{pa}(x_i)) - z_i = 0$
    \EndIf
  \If{$X_i$ is discrete}
    \State Determine $x_i$ such that $x_i = \min \left\{ x : z_i \le h(x \mid \text{pa}(x_i)) \right\}$
  \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}


\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{img/sampling.png}
\caption{One sampling iteration for the three variables from the estimated transformation functions $h(x_i \mid \text{pa}(x_i))$. The latent values $z_i$ are sampled from the standard logistic distribution. The values $x_i$ are determined by applying the inverse of the transformation function for continuous variables or by finding the corresponding category for the ordinal variable.}
\label{fig:sampling}
\end{figure}


\textbf{Interventional sampling} To sample from the interventional distribution, we can apply the do-operator as described by \citet{pearl1995} (Pearl named it set instead of do). The do-operator fixes a variable at a certain value and sample from the distribution of the other variables while keeping the fixed variable constant. For example, if one wants to intervene on $X_2$ and set it to a specific value $\alpha$, $\textcolor{red}{\text{do}(x_2 = \alpha})$
and then sample from the interventional-distribution
\[
x_3 = \min \left\{ x : z_3 \le h(x \mid x_1, \textcolor{red}{x_2 = \alpha}) \right\}
\]

with the same process as for the observational sampling, with the only difference that the intervened variable $X_2$ stays constant.





\textbf{Counterfactual queries} In a counterfactual query one wants to know what the value of variable $X_i$ would have been if another variable $X_j$ had a different value than what was acutally observed. \citet{pearl_book2009} describes the three-step process to answer counterfacutal queries as follows: Given a causal model $M$ and observed evidence $e$ (which are the actually observed values of the variables $X_i$ of one sample) one wants to compute the probability of $Y=y$ under the hypothetical condition $X=x$.

Step 1 aims to explain the past (Z) by knowledge of the evidence e; 
Step 2 amends the past to the hypothetical condition $X=x$ 
Step 3 predicts the future (Y) based on our new understanding of the past and our newly established condition, $X =x$

Pearl named these three steps, (1) abduction,  (2) action and (3) prediction. The procedure is described in the pseudocode \ref{alg:counterfactual} and illustrated in Figure.

\begin{algorithm}
\caption{Answer a Single Counterfactual Query}
\label{alg:single_cf}
\begin{algorithmic}[1]
\State \textbf{Given:} A structural model $X_k = f(Z_k, \text{pa}(X_k))$, with inverse noise map $Z_k = h(X_k \mid \text{pa}(X_k))$
\State \textbf{Input:} Observed sample $x$, intervention $X_i := \alpha$, target variable $X_j$
\vspace{0.3em}
\State \textbf{Step 1: Abduction} Infer latent variable $Z_j = h(x_j \mid \text{pa}(x_j))$ using the observed values
\vspace{0.3em}
\State \textbf{Step 2: Action} Replace the value of $X_i$ with $\alpha$ in the set of parent variables
\vspace{0.3em}
\State \textbf{Step 3: Prediction} Compute the counterfactual value $x_j^{cf} = h_j^{-1}(Z_j \mid \text{pa}(x_j)^{cf})$
\vspace{0.3em}
\end{algorithmic}
\end{algorithm}



While the probability of Y under the hypothetical condition $X=x$ can be determined in any case, the actual counterfactual value of Y is only defined for a continuous outcome but not for discrete outcomes.

% see pearl book causality: 1.4.4 Counterfactuals in Functional Models (page 36)

(What pearl writes:  Likewise, in contrast with the potential-outcome framework, counterfactuals in the structural account are not treated as undefined primitives but rather as quantities to be derived from the more fundamental concepts of causal mechanisms and their structure. )





\section{Individualized Treatment Effect (ITE)}


% https://ascpt.onlinelibrary.wiley.com/doi/epdf/10.1002/cpt.3159
% --> perfect introduction and overview and assumptions also in observatinoal setting about ITE with causal ML --> check it!
% also limitations and how to validate models


\citet{curth2024} provide a comprehensive overview of the individualized treatment effect (ITE) and its estimation in the context of causal machine learning. They state its importance in comparison to average treatment effects, the assumpitons that need to be fulfilled, what kind of limiations typically are encountered and how models should be validated.


% mostly chatgpt

Randomized controlled trials (RCTs) are considered the gold standard for estimating causal effects due to their ability to eliminate confounding through randomization. However, RCTs typically report the \textit{average treatment effect (ATE)}, which summarizes the effect of a treatment across an entire study population. This obscures individual-level variation in treatment response: some individuals may benefit substantially, others not at all, or even be harmed. In personalized medicine and risk-based decision-making, such population-level summaries are insufficient. Instead, the objective is to guide treatment decisions tailored to individual patient characteristics, for which the \textit{individualized treatment effect (ITE)} is a more appropriate target. Where the homogeneous treatment effect refers to the part of the effect that is equal for all patients, the heterogeneous treatment effect describes the non-random variation in treatment effects across individuals or groups. 

\textbf{The Potential Outcomes Framework } Causal inference is commonly formalized within the \textit{Rubin Causal Model}, also known as the potential outcomes framework. For each individual $i$, let $Y_i(1)$ denote the potential outcome under treatment, and $Y_i(0)$ the outcome under control. The individual treatment effect is defined as
\begin{equation}
\tau_i = Y_i(1) - Y_i(0).
\end{equation}
However, only one of the two potential outcomes can be observed for each individual, which constitutes the \textit{fundamental problem of causal inference}. Related estimands include the \textit{conditional average treatment effect (CATE)},
\begin{equation}
\tau(x) = \mathbb{E}[Y(1) - Y(0) \mid X = x],
\end{equation}
which reflects the expected effect conditional on covariates $X = x$, and the more general concept of \textit{heterogeneous treatment effects (HTE)}.

In contrast to the mean-based estimands above, the \textit{quantile treatment effect (QTE)} evaluates differences in the distribution of potential outcomes. For instance, the median treatment effect is defined as
\begin{equation}
\tau^{(0.5)}(x) = Q_{Y(1) \mid X = x}(0.5) - Q_{Y(0) \mid X = x}(0.5),
\end{equation}
where $Q_{Y(t) \mid X = x}(q)$ denotes the $q$-th quantile of the potential outcome under treatment $t$. QTEs are particularly relevant when treatment effects are not symmetrically distributed or when tail behavior is of interest. We will later perform a simulation study using the median for the QTE estimation.

\section{Assumptions for Identifiability}

To identify treatment effects from observational data, several key assumptions are required. \textit{Consistency} ensures that the observed outcome equals the potential outcome under the received treatment. The \textit{Stable Unit Treatment Value Assumption (SUTVA)} assumes no interference between units and that treatments are well-defined. The most critical assumption is \textit{ignorability} (or unconfoundedness), which posits that, conditional on covariates $X$, the treatment assignment is independent of the potential outcomes:
\begin{equation}
(Y(1), Y(0)) \perp T \mid X.
\end{equation}
In addition, the \textit{positivity} assumption requires that the probability of receiving each treatment is strictly between 0 and 1 for all covariate strata:

\begin{equation}
0 < P(T = 1 \mid X = x) < 1.
\end{equation}
These assumptions are untestable but are necessary for identifying causal effects from non-randomized data.

\section{Propensity Score Adjustment in Observational Settings}

In the absence of randomization, the \textit{propensity score}, defined as the probability of receiving treatment conditional on covariates $X$,
\begin{equation}
e(X) = P(T = 1 \mid X),
\end{equation}
can be used to balance treatment groups and reduce confounding rosenbaum1983central. When the ignorability assumption holds, adjusting for the propensity score allows for unbiased estimation of average treatment effects. However, while propensity score methods (e.g., matching, stratification, weighting) are effective for estimating population-level quantities like the ATE, they are often insufficient for ITE estimation. Since ITE requires modeling both potential outcomes at the individual level, direct modeling approaches such as outcome regression, meta-learners, or Bayesian models are typically more appropriate rubin2007design, nie2021quasi. Moreover, reliance on the propensity score alone may fail to capture fine-grained individual heterogeneity necessary for personalized treatment decisions ali2019addressing.



% \section{Individualized Treatment Effect}
% 
% % following mainly chatgpt
% 
% In causal inference, the individualized treatment effect (ITE), quantifies the difference in potential outcomes for a single individual under treatment and control. Formally, for an individual $i$, the ITE is defined as
% 
% \begin{equation}
% \tau_i = Y_i(1) - Y_i(0),
% \end{equation}
% where $Y_i(1)$ and $Y_i(0)$ denote the potential outcomes under treatment and control, respectively. Closely related concepts include the conditional average treatment effect (CATE), defined as the average treatment effect conditional on covariates $X = x$:
% \begin{equation}
% \tau(x) = \mathbb{E}[Y(1) - Y(0) \mid X = x],
% \end{equation}
% and the broader notion of heterogeneous treatment effects (HTE), which refers to any variation in treatment effects across individuals or subpopulations. In applied fields such as marketing, uplift modeling is a term used to describe models that target individuals most likely to benefit from a treatment, essentially estimating the ITE without necessarily relying on a formal causal framework.
% 
% Estimating ITEs is of particular importance in personalized medicine, policy targeting, and risk-based decision-making, where treatment decisions must be tailored to individual characteristics. Unlike standard predictive modeling, which estimates expected outcomes $\mathbb{E}[Y \mid X]$, ITE estimation requires assumptions about counterfactual outcomes and typically involves modeling both treated and untreated potential outcomes. Accurate estimation is challenging due to the fundamental problem of causal inference: only one potential outcome is observed per individual.
% 
% 
% Estimation of the individualized treatment effect relies on several fundamental assumptions to ensure identifiability of causal effects from observational data. A central assumption is consistency, which requires that the observed outcome corresponds to the potential outcome under the treatment actually received: $Y = Y(1)$ if $T = 1$, and $Y = Y(0)$ if $T = 0$. The \textit{Stable Unit Treatment Value Assumption (SUTVA)} ensures no interference between units and that treatments are well-defined. Crucially, the \textit{ignorability} or \textit{unconfoundedness} assumption requires that, conditional on observed covariates $X$, the treatment assignment is independent of the potential outcomes:
% \begin{equation}
% (Y(1), Y(0)) \perp T \mid X.
% \end{equation}
% 
% This implies that there are no unmeasured confounders affecting both treatment and outcome. Additionally, the \textit{positivity} or \textit{overlap} assumption requires that every individual has a non-zero probability of receiving each treatment level:
% \begin{equation}
% 0 < P(T = 1 \mid X = x) < 1 \quad \text{for all } x.
% \end{equation}
% 
% Violation of this condition leads to lack of support and unstable estimates in regions of the covariate space. Together, these assumptions enable identification of causal effects from observed data and form the basis for model-based or algorithmic estimation of ITEs. In practice, these conditions are untestable and must be justified based on subject-matter knowledge and study design.
% 
% 


Rubins potential outcomes framework.

Quantile Treatment effect




- also talk about propensity score Rubin(2007) to basically estimate an RCT...and overcome the problem of confounding. but this might work for ATE but not really for ITE, direct modelling of the outcome is necessary % https://pmc.ncbi.nlm.nih.gov/articles/PMC5920646/


\textbf{Models for ITE Estimation}



% \citet{hoogland2021} gave guidance on how ITE estimation should be performed. A crucial aspect is the consideration is the model complexity and the susceptibility to overfitting. Also the decision whether a HGL or HTE model should be applied. (Especially include stuff from Practical Considerations part , quite good)
% RCTs only measure the average treatment effect. There will be patients who respond better or worse to the treatment because patient specific characteristcs. In personalized medicine however, the aim is to find the optimal treatment for a specific individual. Such a measure that can help in decision making is the ITE.

Assessing predictive performance with AUC, calibration slope, and brier score. In Leo presentation, he says that recalibration can either be done with deviance statistics or by leave one out (loo) cross validation the slope of this regression would then be the estimated shrinkage factor.
T-learner vs s-learner, metalearner, virtual twins

The ITE for a binary endpoint is estimated as the difference of two probabilities (the risk under treatment minus the risk under control). It is essential that the model used to estimate these probabilities is well calibrated and generalizes to new (unseen) data. \citep{guo2017} point out that even though modern neural networks became much more accurate in terms of prediction performance, they are no longer well-calibrated. As it may not be a big problem for the sole purpose of making good predictions, it is very problematic for applications where an accurate quantification of the uncertainty is needed. When using models that are estimated with conventional methods such as ordinary least squares or standard maximum likelihood, they tend to overfit on the training data and make too extreme predictions on the test data. This problem increases with reduced sample size, low event rate or large number of predictor variables. To prevent such overfitting in regression models, penalization (shrinkage) methods are proposed as they shrink the estimated coefficients towards zero to reduce the variance in predictions on new data \citep{riley2021}. 



Logistic regression, penalized logistic regression (shrinkage, lasso
Shrinkage methods should provide better predictive perfomance on average (cite articles). \citet{calster2020} analyzed different regression shrinkage methods with a binary outcome in a simulation study. They concluded, although the calibration slope improved on average, shrinkage often worked poorly on individual datasets. With small sample size and low number of events per variable the performance of most of these methods were highly variable and should be used with caution in such settings. \citet{riley2021} obtained to similar results in their simulation study. Problems occur, because tuning parameters are often estimated with large uncertainty on the training data and fail to generalize. In both studies the autors pointed out that these penalization methods are more unreliable when needed most, that is when the risk of overfitting may be large.


(Shrinkage shrinks the coefficients so that the calibration slope is improved on a test set. The shrinkage factor can for example be found with n-fold cross validation, as e.g. done by lasso with L1 penalization)

Explain tuning of random forest, with depth number of trees and mtry (ranger?)



Use of instrumental variables (IV) to also estimate CATE in presence of unobserved confounders \citep{nichols2007}, \citep{hartford2017}. \citet{frauen2023} propose a model based on IV that is said to also be applicable on observational data. % check more details, they also have an example DAG, however it is not yet accepted and still under review

% https://www.rfberlin.com/wp-content/uploads/2024/12/24030.pdf good book/paper about instrumental variables, also talks about potential outcomes (but i should maybe not go too much into detial)

% http://www.mit.edu/~vchern/papers/ch_iqr_ema.pdf estimate the quantile treatment effect (heterogeneous) with instrumental variables, it looks very similar to the TRAM-DAG approach


\section{Experiments}

\subsection{TRAM-DAG simulation}

Show easy simulation with 3 variables and in the results the plots of the loss function, the coefficient learning, intercepts, shifts, and the sampling results. The sampling results should show that the sampled data matches the DGP very well. Also show the estimated parameters of the linear shifts and the intercepts. The complex shift can be shown by plotting the transformation function of X3 with respect to X2. also some queries for observational, interventional and counterfactual.

\subsection{TRAM-DAG real data}

maybe the Weather data case, or another if we find a practical observational data example.

\subsection{ITE simulations}

Reason to do experiment is the findings of Holly, now we want to show types of models that will be applied and dgp and when problems occure.

In this thesis , I will apply Lasso regression on the IST stroke trial and simulation studies, where the sample size is relatively large.


simulation studies
 "The setup was such that development and test sets were generated from the same data generating mechanism. In practice, there may be differences between these two settings that are not captured by the models, and the uncertainty that accompanies these unknowns may overshadow relatively small gains realized by more complex models."
 % https://pmc.ncbi.nlm.nih.gov/articles/PMC9291969/#sim9154-bib-0065
 
 "This could include the analysis of individual patient data from multiple randomized trials, or even the use of nonrandomized studies for the estimation of outcome risk under a control condition." this motivates the need for observational modeling.


Problems with ITE: (in an RCT setting)
- to estimate the ITE we must assume un-confoundedness. Does this also apply to itneractions (effect modifiers)? Check how this is handled in the literature.
% https://journals.lww.com/epidem/fulltext/2007/09000/four_types_of_effect_modification__a.6.aspx talks about different types of effect modifiers (not sure if this really contributes to the thesis)
- when there are treatment covariate interactions and these covariates are in the DGP but dropped from the dataset (so unobserved), then the ITE Estimation failed in the simulations. At least when there is only 1 strongly interacting variable and we drop this one. An example could be the psychological condition of a patient which might also affect how the treatment works, this is not a confounder but an effect modifier, and i would assume that this variable is rarely recorede or measured.

- Maybe a good conclusion: because this problematic with missing effect modifiers in RCT data can be a motivation to work with observational data where the dag is very detailed specified with all confounders and interactions, then a tram-dag can be applied. However, there we also have the problem, that important variables are probably also not known/measured...

- question still to answer: the estimated ITE on the train vs test set is equally bad (in terms of scatterplot and RMSE), so why does the ITE-cATE plot and the ITE Outcome plot looks like it discriminates good in the train set but not in the test set? Could the answer be, that the model is overfitting, hence tries to really model the observed outcomes and not the true probabilities, hence when an inportant variable is missing, it could still reasonably well predict the outcome (probability) but these are not the causal relationships anymore, so therefore the ITE estimation is bad on the train and the test set. But the ITE-cATE plot still looks good in the train set, because at least the observed outcomes could be predicted very well.??? still not sure if this is the case and how to proof.

- another point is the effect of the correlation of the variables. If the X's are strongly correlated, and one X with interaction effect is dropped, can the info then still be retreived from the other variables? maybe the effect is then attributed to another correlated variable. --> check with simulations and or theroretical proof.



% Plot mit Regression line: durch die regression line lässt sich die differenz zwischen train und test plots rechts auch nicht erklären. Grund ist vermutlich, dass beim ITE nur die probabilities modelliert werden und beim plot rechts die observed outcomes Y=1 oder Y=0 (was ja die optimierungsgrösse im modell fitting war).

\subsection{ITE real data}

% describe the data of stroke trial https://pubmed.ncbi.nlm.nih.gov/9174558/
Results on IST trial wiht the interpretation in the discussion part.

show results of different models including tram dag.

- maybe also make propensity score estimation on IST stroke trial to check if possibly confounded.



\section{Software}

All code was done in R wiht packages xx ussed for yy.




Maybe it is the methods section. Here however, we give a couple hints.
Note that you can wisely use \rr{preamble}-chunks. Minimal, is likely:


\bigskip

\hrule
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
library(knitr)
opts_chunk$set(
    fig.path='figure/ch02_fig',
    self.contained=FALSE,
    cache=TRUE
)
\end{verbatim}
\end{kframe}
\end{knitrout}
\hrule

\bigskip

Defining figure options is very helpful:


\bigskip


\hrule
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
library(knitr)
opts_chunk$set(fig.path='figure/ch02_fig',
               echo=TRUE, message=FALSE,
               fig.width=8, fig.height=2.5,
               out.width='\\textwidth-3cm',
               message=FALSE, fig.align='center',
               background="gray98", tidy=FALSE, #tidy.opts=list(width.cutoff=60),
               cache=TRUE
)
options(width=74)
\end{verbatim}
\end{kframe}
\end{knitrout}
\hrule

\bigskip

This options are best placed in the main document at the beginning. Otherwise a \verb+cache=FALSE+ as knitr option is necessary to overrule a possible  \verb+cache=TRUE+ flag.

\bigskip

Notice how in Figure~\ref{f02:1} everything is properly scaled.

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-3-1} 

}


\end{knitrout}
  \caption{Test figure to illustrate figure options used by knitr.}
  \label{f02:1}
\end{figure}


\section{Citations}

Recall the difference between \verb+\citet{}+ (e.g., \citet{Chu:Geor:99}), \verb+\citep{}+ (e.g., \citep{Chu:Geor:99}) and \verb+\citealp{}+ (e.g., \citealp{Chu:Geor:99}).
For simplicity, we include here all references in the file \verb+biblio.bib+ with the command \verb+\nocite{*}+.\nocite{*}

