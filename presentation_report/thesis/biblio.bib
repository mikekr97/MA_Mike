% Some sample entries...

% Be consistent with either Journal abbreviations or full descriptions.
% `Number` may be missing for some journal articles.
% Carful with captialization of journal titles, use, e.g., {Bayesian}, {Markov} chain {Monte Carlo}, ...

% There is no unique rule whether to include the address of the publisher for books. Be consistent.\
% example Chu:Geor:99 is the most minimal one.

% Additional fields may be present. Spacing and capitalization of the fields are not relevant. 

@ARTICLE{Porc:Furr:Nych:21,
  AUTHOR = 	 {Emilio Porcu and Reinhard Furrer and Douglas Nychka},
  TITLE = 	 {30 Years of Space-time Covariance Functions},
  JOURNAL = 	 {Wiley Interdiscip. Rev. Comput. Stat.},
  FJOURNAL = 	 {Wiley Interdisciplinary Reviews. Computational Statistics},
  YEAR = 	 {2020},
  DOI =          {10.1002/wics.1512},
  VOLUME = 	 {13:e1512},
  PAGES = 	 {1--24},
}


@INPROCEEDINGS{Wang:Furr:20,
  AUTHOR = 	 {Craig Wang and Reinhard Furrer},
  TITLE = 	 {Monte {Carlo} Permutation Tests for Assessing Spatial Dependence at Different Scales},
  EDITOR =       {{La Rocca}, M. and Liseo, B. and Salmaso, L.},
  BOOKTITLE =    {Nonparametric Statistics. ISNPS 2018. Springer Proceedings in Mathematics \& Statistics},
  PUBLISHER =    {Springer},
  YEAR = 	 {2020},
  DOI =          {10.1007/978-3-030-57306-5_45},
  VOLUME = 	 {339},
  PAGES = 	 {503--511},
}

@Manual{varrank,
    title = {varrank: an {R} package for variable ranking based on mutual
             information with applications to observed systemic datasets},
    author = {Gilles Kratzer and Reinhard Furrer},
    year = {2018},
    note = {R package version 0.3},
    url = {https://CRAN.R-project.org/package=varrank},
}


@inbook {Hurr:etal:13,
title = {An Overview of the {North} {Atlantic} Oscillation},
author = {Hurrell, James W. and Kushnir, Yochanan and Ottersen, Geir and Visbeck, Martin},
publisher = {American Geophysical Union},
isbn = {9781118669037},
doi = {10.1029/134GM01},
pages = {1--35},
booktitle = {The North Atlantic Oscillation: Climatic Significance and Environmental Impact},
year = {2013},
}


@Book{Chu:Geor:99,
  author = 	 {Eleanor Chu and Alan George},
  title = 	 {Inside the FFT Black Box: Serial and Parallel Fast Fourier Transform Algorithms},
  publisher = 	 {CRC Press},
  year = 	 {1999},
}

@book{Coll:14,
  title={Modelling Survival Data in Medical Research},
  edition={Third},
  author={Collett, D.},
  series={Chapman \& Hall/CRC Texts in Statistical Science},
  year={2014},
  publisher={Taylor \& Francis}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{pearl2009,
author = {Judea Pearl},
title = {{Causal inference in statistics: An overview}},
volume = {3},
journal = {Statistics Surveys},
number = {none},
publisher = {Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist., and the Statist. Soc. Canada},
pages = {96 -- 146},
keywords = {causal effects, causes of effects, confounding, counterfactuals, graphical methods, mediation, policy evaluation, potential-outcome, structural equation models},
year = {2009},
doi = {10.1214/09-SS057},
URL = {https://doi.org/10.1214/09-SS057}
}

@article{dawid2000,
 ISSN = {01621459, 1537274X},
 URL = {http://www.jstor.org/stable/2669377},
 abstract = {A popular approach to the framing and answering of causal questions relies on the idea of counterfactuals: outcomes that would have been observed had the world developed differently; for example, if the patient had received a different treatment. By definition, one can never observe such quantities, nor assess empirically the validity of any modeling assumptions made about them, even though one's conclusions may be sensitive to these assumptions. Here I argue that for making inference about the likely effects of applied causes, counterfactual arguments are unnecessary and potentially misleading. An alternative approach, based on Bayesian decision analysis, is presented. Properties of counterfactuals are relevant to inference about the likely causes of observed effects, but close attention then must be given to the nature and context of the query, as well as to what conclusions can and cannot be supported empirically. In particular, even in the absence of statistical uncertainty, such inferences may be subject to an irreducible degree of ambiguity.},
 author = {A. P. Dawid},
 journal = {Journal of the American Statistical Association},
 number = {450},
 pages = {407--424},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Causal Inference Without Counterfactuals},
 urldate = {2025-07-03},
 volume = {95},
 year = {2000}
}


@article{hariton2018,
author = {Hariton, Eduardo and Locascio, Joseph J},
title = {Randomised controlled trials - the gold standard for effectiveness research},
journal = {BJOG: An International Journal of Obstetrics \& Gynaecology},
volume = {125},
number = {13},
pages = {1716 -- 1716},
doi = {https://doi.org/10.1111/1471-0528.15199},
url = {https://obgyn.onlinelibrary.wiley.com/doi/abs/10.1111/1471-0528.15199},
eprint = {https://obgyn.onlinelibrary.wiley.com/doi/pdf/10.1111/1471-0528.15199},
year = {2018}
}


@article{nichols2007,
author = {Austin Nichols},
title ={Causal Inference with Observational Data},
journal = {The Stata Journal},
volume = {7},
number = {4},
pages = {507 -- 541},
year = {2007},
doi = {10.1177/1536867X0800700403},
URL = { https://doi.org/10.1177/1536867X0800700403},
eprint = { https://doi.org/10.1177/1536867X0800700403},
abstract = { Problems with inferring causal relationships from nonexperimental data are
                    briefly reviewed, and four broad classes of methods designed to allow estimation
                    of and inference about causal parameters are described: panel regression,
                    matching or reweighting, instrumental variables, and regression discontinuity.
                    Practical examples are offered, and discussion focuses on checking required
                    assumptions to the extent possible. }
}



@article {freedman1987,
	Title = {Equipoise and the ethics of clinical research},
	Author = {Freedman, Benjamin},
	DOI = {10.1056/nejm198707163170304},
	Number = {3},
	Volume = {317},
	Month = {July},
	Year = {1987},
	Journal = {The New England journal of medicine},
	ISSN = {0028-4793},
	Pages = {141--145},
	Abstract = {The ethics of clinical research requires equipoise--a state of genuine uncertainty on the part of the clinical investigator regarding the comparative therapeutic merits of each arm in a trial. Should the investigator discover that one treatment is of superior therapeutic merit, he or she is ethically obliged to offer that treatment. The current understanding of this requirement, which entails that the investigator have no "treatment preference" throughout the course of the trial, presents nearly insuperable obstacles to the ethical commencement or completion of a controlled trial and may also contribute to the termination of trials because of the failure to enroll enough patients. I suggest an alternative concept of equipoise, which would be based on present or imminent controversy in the clinical community over the preferred treatment. According to this concept of "clinical equipoise," the requirement is satisfied if there is genuine uncertainty within the expert medical community--not necessarily on the part of the individual investigator--about the preferred treatment.},
	URL = {https://doi.org/10.1056/NEJM198707163170304}
}




@InProceedings{gutierrez2017,
  title = 	 {Causal Inference and Uplift Modelling: A Review of the Literature},
  author = {Pierre Gutierrez and Jean-Yves G{\'e}rardy},

  booktitle = 	 {Proceedings of The 3rd International Conference on Predictive Applications and APIs},
  pages = 	 {1--13},
  year = 	 {2017},
  editor = 	 {Hardgrove, Claire and Dorard, Louis and Thompson, Keiran and Douetteau, Florian},
  volume = 	 {67},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {11--12 Oct},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf},
  url = 	 {https://proceedings.mlr.press/v67/gutierrez17a.html},
  abstract = 	 {Uplift modeling refers to the set of techniques used to model the incremental impact of an action or treatment on a customer outcome. Uplift modeling is therefore both a Causal Inference problem and a Machine Learning one. The literature on uplift is split into 3 main approaches - the Two-Model approach, the Class Transformation approach and modeling uplift directly. Unfortunately, in the absence of a common framework of causal inference and notation, it can be quite difficult to assess those three methods. In this paper, we use the Rubin (1974) model of causal inference and its modern “econometrics” notation to provide a clear comparison of the three approaches and generalize one of them. To our knowledge, this is the first paper that provides a unified review of the uplift literature. Moreover, our paper contributes to the literature by showing that, in the limit, minimizing the Mean Square Error (MSE) formula with respect to a causal effect estimator is equivalent to minimizing the MSE in which the unobserved treatment effect is replaced by a modified target variable. Finally, we hope that our paper will be of use to researchers interested in applying Machine Learning techniques to causal inference problems in a business context as well as in other fields: medicine, sociology or economics.}
}

@misc{zhao2020,
      title={Uplift Modeling for Multiple Treatments with Cost Optimization}, 
      author={Zhenyu Zhao and Totte Harinen},
      year={2020},
      eprint={1908.05372},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1908.05372}, 
}

@misc{sick2025,
  author       = {Beate Sick and Oliver D{\"u}rr},
  title        = {Interpretable Neural Causal Models with TRAM-DAGs},
  note         = {Accepted at the CLeaR 2025 Conference},
  year         = {2025},
  eprint       = {2503.16206},
  archivePrefix= {arXiv},
  primaryClass = {stat.ML},
  url          = {https://arxiv.org/abs/2503.16206},
  doi          = {10.48550/arXiv.2503.16206}
}

@book{pearl_book2009,
author = {Pearl, Judea},
title = {Causality: Models, Reasoning and Inference},
year = {2009},
isbn = {052189560X},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd},
abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 3,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.}
}


@inproceedings{poinsot2024,
  author    = {Audrey Poinsot and Alessandro Leite and Nicolas Chesneau and Mich{\`e}le S{\'e}bag and Marc Schoenauer},
title = {Learning structural causal models through deep generative models: methods, guarantees, and challenges},
year = {2024},
isbn = {978-1-956792-04-1},
url = {https://doi.org/10.24963/ijcai.2024/907},
doi = {10.24963/ijcai.2024/907},
abstract = {This paper provides a comprehensive review of deep structural causal models (DSCMs), particularly focusing on their ability to answer counterfactual queries using observational data within known causal structures. It delves into the characteristics of DSCMs by analyzing the hypotheses, guarantees, and applications inherent to the underlying deep learning components and structural causal models, fostering a finer understanding of their capabilities and limitations in addressing different counterfactual queries. Furthermore, it highlights the challenges and open questions in the field of deep structural causal modeling. It sets the stages for researchers to identify future work directions and for practitioners to get an overview in order to find out the most appropriate methods for their needs.},
booktitle = {Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence},
articleno = {907},
numpages = {9},
location = {Jeju, Korea},
series = {IJCAI '24}
}




@article{hothorn2014,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/24772743},
 abstract = {The ultimate goal of regression analysis is to obtain information about the conditional distribution of a response given a set of explanatory variables. This goal is, however, seldom achieved because most established regression models estimate only the conditional mean as a function of the explanatory variables and assume that higher moments are not affected by the regressors. The underlying reason for such a restriction is the assumption of additivity of signal and noise. We propose to relax this common assumption in the framework of transformation models. The novel class of semiparametric regression models proposed herein allows transformation functions to depend on explanatory variables. These transformation functions are estimated by regularized optimization of scoring rules for probabilistic forecasts, e.g. the continuous ranked probability score. The corresponding estimated conditional distribution functions are consistent. Conditional transformation models are potentially useful for describing possible heteroscedasticity, comparing spatially varying distributions, identifying extreme events, deriving prediction intervals and selecting variables beyond mean regression effects. An empirical investigation based on a heteroscedastic varying-coefficient simulation model demonstrates that semiparametric estimation of conditional distribution functions can be more beneficial than kernel-based non-parametric approaches or parametric generalized additive models for location, scale and shape.},
 author = {Torsten Hothorn and Thomas Kneib and Peter B{\"u}hlmann},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {1},
 pages = {3--27},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Conditional transformation models},
 urldate = {2025-05-02},
 volume = {76},
 year = {2014}
}

@INPROCEEDINGS{sick2020,
  author={Sick, Beate and Hathorn, Torsten and D{\"u}rr, Oliver},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={Deep transformation models: Tackling complex regression problems with neural network based transformation models}, 
  year={2021},
  volume={},
  number={},
  pages={2476-2481},
  keywords={Deep learning;Maximum likelihood estimation;Uncertainty;Neural networks;Medical services;Predictive models;Probabilistic logic},
  doi={10.1109/ICPR48806.2021.9413177}}

@misc{chen2025,
      title={Causal Machine Learning Methods for Estimating Personalised Treatment Effects -- Insights on validity from two large trials}, 
      author={Hongruyu Chen and Helena Aebersold and Milo Alan Puhan and Miquel Serra-Burriel},
      year={2025},
      eprint={2501.04061},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.04061}, 
}




@article{hoogland2021,
author = {Hoogland, Jeroen and IntHout, Joanna and Belias, Michail and Rovers, Maroeska M. and Riley, Richard D. and E. Harrell Jr, Frank and Moons, Karel G. M. and Debray, Thomas P. A. and Reitsma, Johannes B.},
title = {A tutorial on individualized treatment effect prediction from randomized trials with a binary endpoint},
journal = {Statistics in Medicine},
volume = {40},
number = {26},
pages = {5961-5981},
keywords = {causal inference, personalized medicine, prediction, regression, treatment effect},
doi = {https://doi.org/10.1002/sim.9154},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9154},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9154},
abstract = {Randomized trials typically estimate average relative treatment effects, but decisions on the benefit of a treatment are possibly better informed by more individualized predictions of the absolute treatment effect. In case of a binary outcome, these predictions of absolute individualized treatment effect require knowledge of the individual's risk without treatment and incorporation of a possibly differential treatment effect (ie, varying with patient characteristics). In this article, we lay out the causal structure of individualized treatment effect in terms of potential outcomes and describe the required assumptions that underlie a causal interpretation of its prediction. Subsequently, we describe regression models and model estimation techniques that can be used to move from average to more individualized treatment effect predictions. We focus mainly on logistic regression-based methods that are both well-known and naturally provide the required probabilistic estimates. We incorporate key components from both causal inference and prediction research to arrive at individualized treatment effect predictions. While the separate components are well known, their successful amalgamation is very much an ongoing field of research. We cut the problem down to its essentials in the setting of a randomized trial, discuss the importance of a clear definition of the estimand of interest, provide insight into the required assumptions, and give guidance with respect to modeling and estimation options. Simulated data illustrate the potential of different modeling options across scenarios that vary both average treatment effect and treatment effect heterogeneity. Two applied examples illustrate individualized treatment effect prediction in randomized trial data.},
year = {2021}
}


@article{herzog2023,
author = {Herzog, Lisa and Kook, Lucas and G{\"o}tschi, Andrea and Petermann, Katrin and H{\"a}nsel, Martin and Hamann, Janne and D{\"u}rr, Oliver and Wegener, Susanne and Sick, Beate},
title = {Deep transformation models for functional outcome prediction after acute ischemic stroke},
journal = {Biometrical Journal},
volume = {65},
number = {6},
pages = {2100379},
keywords = {deep learning, distributional regression, ordinal regression, transformation models},
doi = {https://doi.org/10.1002/bimj.202100379},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202100379},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202100379},
abstract = {Abstract In many medical applications, interpretable models with high prediction performance are sought. Often, those models are required to handle semistructured data like tabular and image data. We show how to apply deep transformation models (DTMs) for distributional regression that fulfill these requirements. DTMs allow the data analyst to specify (deep) neural networks for different input modalities making them applicable to various research questions. Like statistical models, DTMs can provide interpretable effect estimates while achieving the state-of-the-art prediction performance of deep neural networks. In addition, the construction of ensembles of DTMs that retain model structure and interpretability allows quantifying epistemic and aleatoric uncertainty. In this study, we compare several DTMs, including baseline-adjusted models, trained on a semistructured data set of 407 stroke patients with the aim to predict ordinal functional outcome three months after stroke. We follow statistical principles of model-building to achieve an adequate trade-off between interpretability and flexibility while assessing the relative importance of the involved data modalities. We evaluate the models for an ordinal and dichotomized version of the outcome as used in clinical practice. We show that both tabular clinical and brain imaging data are useful for functional outcome prediction, whereas models based on tabular data only outperform those based on imaging data only. There is no substantial evidence for improved prediction when combining both data modalities. Overall, we highlight that DTMs provide a powerful, interpretable approach to analyzing semistructured data and that they have the potential to support clinical decision-making.},
year = {2023}
}


@misc{kingma2015,
title={Adam: A Method for Stochastic Optimization}, 
note={Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
author={Diederik P. Kingma and Jimmy Ba},
year={2015},
eprint={1412.6980},
archivePrefix={arXiv},
primaryClass={cs.LG},
url={https://arxiv.org/abs/1412.6980},
doi={10.48550/arXiv.1412.6980},
}

@article{hothorn2018,
author = {Hothorn, Torsten and M{\"o}st, Lisa and B{\"u}hlmann, Peter},
title = {Most Likely Transformations},
journal = {Scandinavian Journal of Statistics},
volume = {45},
number = {1},
pages = {110-134},
keywords = {censoring, conditional distribution function, conditional quantile function, distribution regression, transformation model, truncation},
doi = {https://doi.org/10.1111/sjos.12291},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/sjos.12291},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/sjos.12291},
abstract = {Abstract We propose and study properties of maximum likelihood estimators in the class of conditional transformation models. Based on a suitable explicit parameterization of the unconditional or conditional transformation function, we establish a cascade of increasingly complex transformation models that can be estimated, compared and analysed in the maximum likelihood framework. Models for the unconditional or conditional distribution function of any univariate response variable can be set up and estimated in the same theoretical and computational framework simply by choosing an appropriate transformation function and parameterization thereof. The ability to evaluate the distribution function directly allows us to estimate models based on the exact likelihood, especially in the presence of random censoring or truncation. For discrete and continuous responses, we establish the asymptotic normality of the proposed estimators. A reference software implementation of maximum likelihood-based estimation for conditional transformation models that allows the same flexibility as the theory developed here was employed to illustrate the wide range of possible applications.},
year = {2018}
}

@article{pearl1995,
 ISSN = {00063444, 14643510},
 URL = {http://www.jstor.org/stable/2337329},
 abstract = {The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained.},
 author = {Judea Pearl},
 journal = {Biometrika},
 number = {4},
 pages = {669--688},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Causal Diagrams for Empirical Research},
 urldate = {2025-05-31},
 volume = {82},
 year = {1995}
}





@misc{zheng2018,
      title={DAGs with NO TEARS: Continuous Optimization for Structure Learning}, 
      author={Xun Zheng and Bryon Aragam and Pradeep Ravikumar and Eric P. Xing},
      year={2018},
      eprint={1803.01422},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1803.01422}, 
}


@article{curth2024,
author = {Curth, Alicia and Peck, Richard W. and McKinney, Eoin and Weatherall, James and van der Schaar, Mihaela},
title = {Using Machine Learning to Individualize Treatment Effect Estimation: Challenges and Opportunities},
journal = {Clinical Pharmacology \& Therapeutics},
volume = {115},
number = {4},
pages = {710-719},
doi = {https://doi.org/10.1002/cpt.3159},
url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt.3159},
eprint = {https://ascpt.onlinelibrary.wiley.com/doi/pdf/10.1002/cpt.3159},
abstract = {The use of data from randomized clinical trials to justify treatment decisions for real-world patients is the current state of the art. It relies on the assumption that average treatment effects from the trial can be extrapolated to patients with personal and/or disease characteristics different from those treated in the trial. Yet, because of heterogeneity of treatment effects between patients and between the trial population and real-world patients, this assumption may not be correct for many patients. Using machine learning to estimate the expected conditional average treatment effect (CATE) in individual patients from observational data offers the potential for more accurate estimation of the expected treatment effects in each patient based on their observed characteristics. In this review, we discuss some of the challenges and opportunities for machine learning to estimate CATE, including ensuring identification assumptions are met, managing covariate shift, and learning without access to the true label of interest. We also discuss the potential applications as well as future work and collaborations needed to further improve identification and utilization of CATE estimates to increase patient benefit.},
year = {2024}
}



@inproceedings{reisach2021,
author = {Reisach, Alexander G. and Seiler, Christof and Weichwald, Sebastian},
title = {Beware of the simulated DAG! causal discovery benchmarks may be easy to game},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Simulated DAG models may exhibit properties that, perhaps inadvertently, render their structure identifiable and unexpectedly affect structure learning algorithms. Here, we show that marginal variance tends to increase along the causal order for generically sampled additive noise models. We introduce varsortability as a measure of the agreement between the order of increasing marginal variance and the causal order. For commonly sampled graphs and model parameters, we show that the remarkable performance of some continuous structure learning algorithms can be explained by high varsortability and matched by a simple baseline method. Yet, this performance may not transfer to real-world data where varsortability may be moderate or dependent on the choice of measurement scales. On standardized data, the same algorithms fail to identify the ground-truth DAG or its Markov equivalence class. While standardization removes the pattern in marginal variance, we show that data generating processes that incur high varsortability also leave a distinct covariance pattern that may be exploited even after standardization. Our findings challenge the significance of generic benchmarks with independently drawn parameters.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {2127},
numpages = {13},
series = {NIPS '21}
}

@article{friedman2010,
 title={Regularization Paths for Generalized Linear Models via Coordinate Descent},
 volume={33},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v033i01},
 doi={10.18637/jss.v033.i01},
 number={1},
 journal={Journal of Statistical Software},
 author={Friedman, Jerome H. and Hastie, Trevor and Tibshirani, Rob},
 year={2010},
 pages={1-22}
}

@article{breiman2001,
author = {Breiman, Leo},
title = {Random Forests},
year = {2001},
issue_date = {October 1 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {45},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1023/A:1010933404324},
doi = {10.1023/A:1010933404324},
journal = {Mach. Learn.},
month = oct,
pages = {5-32},
numpages = {28},
keywords = {classification, ensemble, regression}
}

@article{calster2020,
author = {Ben Van Calster and Maarten van Smeden and Bavo De Cock and Ewout W Steyerberg},
title ={Regression shrinkage methods for clinical prediction models do not guarantee improved performance: Simulation study},

journal = {Statistical Methods in Medical Research},
volume = {29},
number = {11},
pages = {3166-3178},
year = {2020},
doi = {10.1177/0962280220921415},
    note ={PMID: 32401702},

URL = { https://doi.org/10.1177/0962280220921415},
eprint = { 
        https://doi.org/10.1177/0962280220921415
}
,
    abstract = { When developing risk prediction models on datasets with limited sample size, shrinkage methods are recommended. Earlier studies showed that shrinkage results in better predictive performance on average. This simulation study aimed to investigate the variability of regression shrinkage on predictive performance for a binary outcome. We compared standard maximum likelihood with the following shrinkage methods: uniform shrinkage (likelihood-based and bootstrap-based), penalized maximum likelihood (ridge) methods, LASSO logistic regression, adaptive LASSO, and Firth’s correction. In the simulation study, we varied the number of predictors and their strength, the correlation between predictors, the event rate of the outcome, and the events per variable. In terms of results, we focused on the calibration slope. The slope indicates whether risk predictions are too extreme (slope < 1) or not extreme enough (slope > 1). The results can be summarized into three main findings. First, shrinkage improved calibration slopes on average. Second, the between-sample variability of calibration slopes was often increased relative to maximum likelihood. In contrast to other shrinkage approaches, Firth’s correction had a small shrinkage effect but showed low variability. Third, the correlation between the estimated shrinkage and the optimal shrinkage to remove overfitting was typically negative, with Firth’s correction as the exception. We conclude that, despite improved performance on average, shrinkage often worked poorly in individual datasets, in particular when it was most needed. The results imply that shrinkage methods do not solve problems associated with small sample size or low number of events per variable. }
}


@article{riley2021,
title = {Penalization and shrinkage methods produced unreliable clinical prediction models especially when sample size was small},
journal = {Journal of Clinical Epidemiology},
volume = {132},
pages = {88-96},
year = {2021},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2020.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0895435620312099},
author = {Richard D. Riley and Kym I.E. Snell and Glen P. Martin and Rebecca Whittle and Lucinda Archer and Matthew Sperrin and Gary S. Collins},
keywords = {Risk prediction models, Penalization, Shrinkage, Overfitting, Sample size},
abstract = {Objectives
When developing a clinical prediction model, penalization techniques are recommended to address overfitting, as they shrink predictor effect estimates toward the null and reduce mean-square prediction error in new individuals. However, shrinkage and penalty terms (‘tuning parameters’) are estimated with uncertainty from the development data set. We examined the magnitude of this uncertainty and the subsequent impact on prediction model performance.
Study Design and Setting
This study comprises applied examples and a simulation study of the following methods: uniform shrinkage (estimated via a closed-form solution or bootstrapping), ridge regression, the lasso, and elastic net.
Results
In a particular model development data set, penalization methods can be unreliable because tuning parameters are estimated with large uncertainty. This is of most concern when development data sets have a small effective sample size and the model's Cox-Snell R2 is low. The problem can lead to considerable miscalibration of model predictions in new individuals.
Conclusion
Penalization methods are not a ‘carte blanche’; they do not guarantee a reliable prediction model is developed. They are more unreliable when needed most (i.e., when overfitting may be large). We recommend they are best applied with large effective sample sizes, as identified from recent sample size calculations that aim to minimize the potential for model overfitting and precisely estimate key parameters.}
}


@inproceedings{guo2017,
  author       = {Chuan Guo and
                  Geoff Pleiss and
                  Yu Sun and
                  Kilian Q. Weinberger},
  editor       = {Doina Precup and
                  Yee Whye Teh},
  title        = {On Calibration of Modern Neural Networks},
  booktitle    = {Proceedings of the 34th International Conference on Machine Learning,
                  {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series       = {Proceedings of Machine Learning Research},
  volume       = {70},
  pages        = {1321--1330},
  publisher    = {{PMLR}},
  year         = {2017},
  url          = {http://proceedings.mlr.press/v70/guo17a.html},
  timestamp    = {Wed, 02 Oct 2024 14:40:04 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/GuoPSW17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hartford2017,
author = {Hartford, Jason and Lewis, Greg and Leyton-Brown, Kevin and Taddy, Matt},
title = {Deep IV: a flexible approach for counterfactual prediction},
year = {2017},
publisher = {JMLR.org},
abstract = {Counterfactual prediction requires understanding causal relationships between so-called treatment and outcome variables. This paper provides a recipe for augmenting deep learning methods to accurately characterize such relationships in the presence of instrument variables (IVs)-sources of treatment randomization that are conditionally independent from the outcomes. Our IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose loss function involves integration over the conditional treatment distribution. This Deep IV framework allows us to take advantage of off-the-shelf supervised learning techniques to estimate causal effects by adapting the loss function. Experiments show that it outperforms existing machine learning approaches.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {1414--1423},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}



@misc{frauen2023,
      title={Estimating individual treatment effects under unobserved confounding using binary instruments}, 
      author={Dennis Frauen and Stefan Feuerriegel},
      note  = {Accepted at ICLR 2023},
      year={2023},
      eprint={2208.08544},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2208.08544}, 
}


@article{IST1997,
title = {The International Stroke Trial (IST): a randomised trial of aspirin, subcutaneous heparin, both, or neither among 19,435 patients with acute ischaemic stroke},
author = {{International Stroke Trial Collaborative Group}},
journal = {The Lancet},
volume = {349},
number = {9065},
pages = {1569-1581},
year = {1997},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(97)04011-7},
url = {https://doi.org/10.1016/S0140-6736(97)04011-7}
}

@article{sandercock2011,
  author    = {Sandercock, Peter A.G. and Niewada, Maciej and Cz{\l}onkowska, Anna and the International Stroke Trial Collaborative Group},
  title     = {The International Stroke Trial database},
  journal   = {Trials},
  year      = {2011},
  volume    = {12},
  number    = {1},
  pages     = {101},
  doi       = {10.1186/1745-6215-12-101},
  url       = {https://doi.org/10.1186/1745-6215-12-101},
  issn      = {1745-6215}
}

