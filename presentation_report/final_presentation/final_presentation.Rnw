% \documentclass[aspectratio=169,onlytextwidth,english]{beamer}
\documentclass[onlytextwidth,english]{beamer}

% use official beamer theme from uzh
\usetheme[english]{uzh} 

% First installation of languages required
% tinytex::tlmgr_install("babel-english")
% tinytex::tlmgr_install("babel-german")


%% load relevant packages:


\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
%\usepackage[english]{babel}
\usepackage{pgfpages}           % necessary for the handouts production
\usepackage{amsmath}            % for nice mathematics
\usepackage{verbatim}           % for verbatim output
\usepackage{wasysym}            % symbols (smilies etc.)
\usepackage{longtable}
\usepackage{float}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{xcolor} % for the color names, see: http://en.wikibooks.org/wiki/LaTeX/Colors#Predefined_
\usepackage{natbib}             % for bibliography style and citations
\usepackage{hyperref}
\usepackage{caption}
\hypersetup{%
    hyperindex=true,
    colorlinks=true,%
    urlcolor = {uzh@blue},% in theme uzh
    citecolor = {uzh@blue},
    urlcolor = {uzh@berry},
    pdfstartview=Fit,%
    pdfpagelayout=SinglePage,%
    pdfpagemode=UseThumbs
  }%
\usepackage{url}
\DeclareOptionBeamer{compress}{\beamer@compresstrue}
\ProcessOptionsBeamer

%% define slidetitle color
\setbeamercolor{title}{fg=uzh@blue}
\setbeamercolor{frametitle}{fg=uzh@blue}


% \title{Neural Causal Models with TRAM-DAGs}
\title{\normalsize Causal Modeling with Neural Networks \\
and Individualized Treatment Effect Estimation}



%% The following are all optional, simply comment them
%\subtitle{Subtitle (optional)}
\institute{Master Program in Biostatistics www.biostat.uzh.ch\\ Master Exam}  %% optional
% leave some vertical space here

% \author{Mike Kr{\"a}henb{\"u}hl, Supervisors: Beate Sick, Oliver D{\"u}rr }

\author{Mike Kr{\"a}henb{\"u}hl \\
Supervisors: Prof. Dr. Beate Sick (UZH), Prof. Dr. Oliver D{\"u}rr (HTWG Konstanz)\\[1ex]}
\date{\today}

\titlegraphic{img/uzh-lake.jpg}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
<<knitr_settings, include=FALSE,purl=FALSE>>=
library(knitr)
opts_chunk$set(
fig.path='figures/', fig.show='hold', fig.height=3.9)

# Packages
library(ggdag)
library(ggplot2)
# library("lme4")
# library("multcomp")
# library("lattice")
# library("tableone")
# library("xtable")
# library("mgcv")
# library("colorspace")
# library("ggplot2")
# library("readxl")

# data
# source("data/NISCI_data.R")

# read midsagittal tissue bridges
# tissue_mid <- read_excel("data/lesion_parameters_LF.xlsx")



@

\begin{document}

\maketitle




\begin{frame}{Background}

\begin{columns}

% Left side: Text (approx. 3/4 of the slide)
\begin{column}{0.7\textwidth}


\textbf{Paper \textit{"Interpretable Neural Causal Models with TRAM-DAGs"} \citep{sick2025}:}
\begin{itemize}
    \item Framework to model causal relationships in a known directed acyclic graph (DAG)
    \item Based on transformation models
    \item Rely on (deep) neural networks
    \item Compromise between interpretability and flexibility
\end{itemize}
\end{column}

% Right side: Image (approx. 1/4 of the slide)
\begin{column}{0.3\textwidth}
\includegraphics[width=\textwidth]{img/TRAM_DAG_Background.png}
\end{column}

\end{columns}

They showed on synthetic data, that TRAM-DAGs can be fitted on observational data and tackle causal queries on all three levels of Pearl's causal hierarchy.

\end{frame}






\begin{frame}{Research Questions}


\textbf{In this presentation:}


\begin{enumerate}
    \item TRAM-DAGs
    
    \begin{itemize}
        \item How to fit the model on observed data and subsequently make observational, interventional and counterfactual queries?
    \end{itemize}
    
    \item Individualized Treatment Effect (ITE) estimation
    \begin{itemize}
        \item Does ITE estimation work on real RCT data (International Stroke Trial)?
        \item When and why does ITE estimation fail (simulation)?
        \item How to estimate ITEs with TRAM-DAGs in a complicated graph (simulation)?
    \end{itemize}
\end{enumerate}
\end{frame}



\begin{frame}[plain]
\centering
\vspace{0.2\textheight}
{\usebeamercolor[fg]{title} \LARGE \textbf{TRAM-DAGs}}
\end{frame}






\begin{frame}{TRAM-DAGs: Motivation}

\vspace{1cm}

\begin{columns}

% Left side: Text
\begin{column}{0.43\textwidth}
\textbf{Randomized Controlled Trial:}
\begin{itemize}
    \item Gold standard for estimating causal effect
    \item Solves problem of confounding
\end{itemize}

\end{column}

% \hspace{0.5cm}

\begin{column}{0.45\textwidth}
\textbf{Observational Data:}
\begin{itemize}
    \item Real world, potential confounding
    \item We assume no unobserved confounding
\end{itemize}
\end{column}

\end{columns}


% Below: image
\includegraphics[width=\textwidth]{img/RCT_Observational.png}


\end{frame}




\begin{frame}{TRAM-DAGs: Motivation}

\textbf{Pearl's causal hierarchy} \citep{pearl_book2009}

\vspace{-0.5cm}

\begin{columns}

% Left side: Text (60%)
\begin{column}{0.7\textwidth}

(L1) Observational: $P(Y=1 \mid E=1)$ \\
{\footnotesize \textit{"Probability of heart disease given that the person exercises"}}

\vspace{0.6cm}

(L2) Interventional: $P(Y=1 \mid \text{do}(E=1))$ \\
{\footnotesize \textit{"Probability of heart disease if we made people start exercising"}} 

\vspace{0.6cm}

(L3) Counterfactual: $P(Y_{(E=1)} = 1 \mid E=0, Y=1)$ \\
{\footnotesize \textit{"Would someone who does not exercise and has heart disease still have it if they had exercised?"}}

\end{column}

% Right side: Image (40%)
\begin{column}{0.33\textwidth}
\includegraphics[width=1\linewidth]{img/Pearls_Ladder.png}
\end{column}

\end{columns}

\end{frame}



% 
% \begin{frame}{Causality: Example}
%     \centering
%     \vspace{0.2cm}
% <<dag_smoking, echo=FALSE, fig.width=3, fig.height=3, out.width="40%">>=
% theme_set(theme_dag())
% 
% # Set custom coordinates
% coord_dag <- list(
%   x = c(smoking = 0, age = 1, exercise = 2, heart = 2),
%   y = c(smoking = 1.3, age = 1.5, exercise = 1.5, heart = 1.3)
% )
% 
% smoking_ca_dag <- dagify(heart ~ smoking + age + exercise,
%   smoking ~ age,
%   labels = c(
%     "heart" = "Heart Disease",
%     "smoking" = "Smoking",
%     "exercise" = "Exercise",
%     "age" = "Age"
%   ),
%   #latent = "unhealthy",
%   exposure = "smoking",
%   outcome = "heart",
%   coords = coord_dag
% )
% 
% # plot with reduced size
% ggdag(smoking_ca_dag, text = FALSE, use_labels = "label") + theme_void()
% 
% 
% # Use label repel to avoid overlap with arrows
% ggdag(smoking_ca_dag, text = TRUE) +
% 	geom_dag_label(aes(label = label, fill = FALSE), 
%                   label.size = 0.2,
%                   size = 3.5, 
%                   color = "black", 
%                   segment.color = "black", 
%                   segment.size = 0.2) +
%   theme_void()
% 
% @
% \end{frame}
\begin{frame}{TRAM-DAGs: Background}

\textbf{Structural Causal Model:} Describes the causal mechanism and probabilistic uncertainty \citep{pearl_book2009}

% \vspace{0.2cm}


{ % start of centering group
\centering
\includegraphics[width=0.85\textwidth]{img/SCM.png}
} 

\begin{itemize}
    \item $X_i$ : observed variable
    \item $Z_i$ : exogeneous (latent) variable
    \item $f_i$ : deterministic function: $X_i = f_i(Z_i, \text{pa}(X_i))$
    % \item $f$ = in our case: $X_2 = f(X_1, U) = h^{-1}(U_{\text{logis}} - \mathbf{x}^\top \boldsymbol{\beta})$
\end{itemize}

$\rightarrow$ We want a model that estimates $X_i = f_i(Z_i, \text{pa}(X_i))$ in a flexible and interpretable way!

% \vfill





\end{frame}





% 
% \begin{frame}{Estimating Functional Form}
% 
% % Statistical Methods
% \begin{columns}
% \begin{column}{0.75\textwidth}
% \textbf{Statistical methods:}
% \begin{itemize}
%     \item E.g. linear/logistic regression
%     \item Predefined form, risk of bias if misspecified
% \end{itemize}
% \end{column}
% \begin{column}{0.23\textwidth}
% \includegraphics[width=\textwidth]{img/conditional_distributions.png}
% \end{column}
% \end{columns}
% 
% \vspace{0.3cm}
% 
% % Neural Networks
% \begin{columns}
% \begin{column}{0.75\textwidth}
% \textbf{Neural networks:}
% \begin{itemize}
%     \item E.g. feed-forward NNs, normalizing flows, VACAs
%     \item Flexible, but "black-box", data-type limitations
% \end{itemize}
% \end{column}
% \begin{column}{0.23\textwidth}
% \includegraphics[width=\textwidth]{img/neural_network.png}
% \end{column}
% \end{columns}
% 
% \vspace{0.3cm}
% 
% % TRAM-DAGs
% \begin{columns}
% \begin{column}{0.75\textwidth}
% \textbf{TRAM-DAGs:}
% \begin{itemize}
%     \item Compromise: flexibility + interpretability
%     \item Mixed data types
% \end{itemize}
% \end{column}
% \begin{column}{0.23\textwidth}
% \includegraphics[width=\textwidth]{img/TRAM_Raw.png}
% \end{column}
% \end{columns}
% 
% \end{frame}






\begin{frame}{TRAM-DAGs: Background}

Proposed framework: TRAM-DAGs \citep{sick2025}

  \centering
  \includegraphics[width=1\linewidth]{img/TRAM_DAG.png}
\end{frame}



\begin{frame}{TRAM-DAGs: Background}

\textbf{Transformation Models}: Flexible distributional regression method \citep{hothorn2014}

\vspace{0.4cm}

\textsb{Continuous } $Y \in \mathbb{R}$: 
\[
F_{Y \mid \mathbf{X} = \mathbf{x}}(y) = F_Z(h(y \mid \mathbf{x})) = F_Z(h(y) + \mathbf{x}^\top \boldsymbol{\beta}) 
\]

\textsb{Discrete } $Y \in \{y_1, y_2, \ldots, y_K\}$: 
\[
P(Y \leq y_k \mid \mathbf{X} = \mathbf{x}) = F_Z(\vartheta_k + \mathbf{x}^\top \boldsymbol{\beta}), \quad k = 1, 2, \ldots, K - 1
\]

\vspace{0.4cm}

\begin{itemize}
    \item $F_Z$: CDF of the latent distribution (e.g. standard logistic)
    \item $h$: Transformation function, monotonically increasing
    \item $\mathbf{x}$: Predictors
\end{itemize}

\end{frame}




% 
% 
% \begin{frame}{Transformation Models}
% 
% \begin{columns}
% 
% % Left column: Continuous Y
% \begin{column}{0.48\textwidth}
% \textbf{Continuous $Y$:}
% 
% {\small
% \vspace{0.2cm}
% Intercept: Bernstein polynomial
% \vspace{0.2cm}
% 
% \scalebox{0.85}{$
% h_I(y) = \frac{1}{M + 1} \sum_{k=0}^{M} \vartheta_k \, \text{B}_{k, M}(y)
% $}
% 
% \vspace{0.2cm}
% 
% \scalebox{0.85}{$
% h(y \mid \mathbf{x}) = h_I(y) - \mathbf{x}^\top \boldsymbol{\beta}
% $}
% }
% 
% \end{column}
% 
% % Right column: Discrete/Ordinal Y
% \begin{column}{0.48\textwidth}
% \textbf{Discrete/Ordinal $Y$:}
% 
% {\small
% 
% \vspace{0.2cm}
% Intercept: Cut-off value
% \vspace{0.2cm}
% 
% \scalebox{0.85}{$
% h_I(y_k) = \vartheta_k
% $}
% 
% \vspace{0.2cm}
% 
% \scalebox{0.85}{$
% h(y_k \mid \mathbf{x}) = h_I(y_k) - \mathbf{x}^\top \boldsymbol{\beta}
% $}
% }
% 
% \end{column}
% 
% \end{columns}
% 
% \vspace{0.3cm}
% \centering
% \includegraphics[width=0.9\textwidth]{img/TRAM_Cont_Ord.png}
% 
% \end{frame}
% 





\begin{frame}{TRAM-DAGs: Background}

\textbf{Extended to Deep TRAMs} \citep{sick2020}
  \begin{itemize}
  \item Customizable transformation model using neural networks (NNs)
  \item Minimizing negative log-likelihood (NLL) via NN optimization
  \end{itemize}

\vspace{0.2cm}
\textsb{Effects of predictors:} LS (Linear Shift), CS (Complex Shift), CI (Complex Intercept)

  \vfill
  \centering
  \includegraphics[width=0.9\linewidth]{img/deep_TRAM.png}
\end{frame}











\begin{frame}{TRAM-DAGs: Experiment 1 (simulation)}

\textbf{Setup:}

  \begin{itemize}
    \item We have:
    \begin{itemize}
      \item Observational data (simulated)
      \item Predefined DAG
    \end{itemize}
    \item We want:
    \begin{itemize}
      \item Estimate $Z_i = h_i(X_i \mid \operatorname{pa}(X_i))$ of each variable $i$
      \item Sample from conditional distributions to make causal queries
    \end{itemize}
  \end{itemize}

  \vfill
  \centering
  \includegraphics[width=0.7\linewidth]{img/Simulation_Example.png}
\end{frame}



% 
% \begin{frame}{Adjacency Matrix}
% 
% Model structure represented by a meta-adjacency matrix:
% 
% \begin{itemize}
%   \item \textbf{Rows}: source of effect
%   \item \textbf{Columns}: target of effect
% \end{itemize}
% 
% \vspace{0.4cm}
% 
% \begin{center}
% \begin{tikzpicture}[baseline={(current bounding box.center)}]
% 
%   % DAG image
%   \node (img) at (0, 0) {\includegraphics[width=0.28\textwidth]{img/DAG_MA.png}};
% 
%   % Matrix
%   \node (matrix) at (5, 0) {
%     $\mathbf{MA} =
%     \begin{bmatrix}
%       0 & \text{LS} & \text{LS} \\
%       0 & 0  & \text{CS} \\
%       0 & 0  & 0
%     \end{bmatrix}$
%   };
% 
%   % Arrow
%   \draw[->, thick] (img.east) -- (matrix.west);
% 
% \end{tikzpicture}
% \end{center}
% 
% \end{frame}



\begin{frame}{TRAM-DAGs: Experiment 1 (simulation)}

\textbf{Data-generating process (DGP):}

\vspace{-1cm}

\begin{columns}

% Left column: Descriptions and formulas
\begin{column}{0.72\textwidth}

\textbf{\(X_1\):} Continuous, bimodal. \textit{Source node} (independent).

\vspace{0.4cm}

\textbf{\(X_2\):} Continuous. Depends on \(X_1\) (\textcolor{red}{linear}):

\vspace{0.15cm}
{\scriptsize
\[
\textcolor{red}{\beta_{12} = 2}, \quad h_I(X_2) = 5 X_2
\]
\[
\boxed{
h(X_2 \mid X_1) = h_I(X_2) + \textcolor{red}{\beta_{12}} X_1
}
\]
}

\vspace{0.4cm}

\textbf{\(X_3\):} Ordinal. Depends on \(X_1\) (\textcolor{red}{linear}) and \(X_2\) (\textcolor{blue}{complex}):

\vspace{0.15cm}
{\scriptsize
\[
\textcolor{red}{\beta_{13} = 0.2}, \quad \textcolor{blue}{f(X_2) = 0.5 \cdot \exp(X_2)}, \quad \vartheta_k \in \{-2,\, 0.42,\, 1.02\}
\]
\[
\boxed{
h(X_{3,k} \mid X_1, X_2) = \vartheta_k + \textcolor{red}{\beta_{13}} X_1 + \textcolor{blue}{f(X_2)}
}
\]
}


\end{column}

% Right column: Plot
\begin{column}{0.28\textwidth}
\includegraphics[width=0.8\linewidth]{img/DGP_Variables.png}
\end{column}

\end{columns}

\end{frame}





% \textbf{Parameters:} 281 total (not all used)
% \begin{itemize}
%     \item Simple Intercepts (SI): \textbf{240} \\
%     - only 43 needed (20 + 20 + 3)
%     \item Linear Shifts (LS): \textbf{9} \\
%     - 2 active
%     \item Complex Shifts (CS): \textbf{32} \\
%     - 24 active
% \end{itemize}

% 
% \begin{frame}{Construct Model: Modular Neural Network}
% 
% \begin{columns}
% 
% % Left side: Text
% \begin{column}{0.65\textwidth}
% 
% \vspace{0.1cm}
% 
% \textbf{Inputs:} \\ Observations + adjacency matrix
% 
% \vspace{0.4cm}
% 
% \textbf{Outputs:}
% \begin{itemize}
%     \item Simple Intercepts (SI): \vartheta
%     \item Linear Shifts (LS): $\beta_{12}X_1, \beta_{13}X_2$
%     \item Complex Shift (CS):  $\beta(X_2)$
% \end{itemize}
% 
% 
% 
% \vspace{0.4cm}
% \textbf{Transformation Functions:} \\
% \begin{align*}
% h(X \mid pa(X)) = \text{SI} + \text{LS} + \text{CS} \\
% & h(X_1) = h_I(X_1) \\
% & h(X_2 \mid X_1) = h_I(X_2) + \textcolor{red}{\beta_{12} X_1} \\
% & h(X_{3,k} \mid X_1, X_2) = \vartheta_k + \textcolor{red}{\beta_{13} X_1} + \textcolor{blue}{\beta(X_2)} 
% % \quad \( h = \text{SI} + \text{LS} + \text{CS} \)
% \end{align*}
% \end{column}
% 
% % Right side: Image
% \begin{column}{0.35\textwidth}
% \begin{figure}
%   \centering
%   \includegraphics[width=0.65\linewidth]{img/CS.png}
%   \caption{$\text{CS}_{X_2}$ on $X_3$}
% \end{figure}
% 
% \end{column}
% 
% \end{columns}
% 
% \end{frame}
% 





\begin{frame}{TRAM-DAGs: Experiment 1 (simulation)}

\textbf{Construct Model: Modular Neural Network}

\begin{columns}

% Left side: Text
\begin{column}{0.65\textwidth}

\vspace{0.1cm}

\textsb{Inputs:} Observations + assumed structure

\vspace{0.2cm}

\textsb{Outputs:}
\begin{itemize}
    \item Simple Intercepts (SI): $\textcolor{violet}{\vartheta}$
    \item Linear Shifts (LS): $\textcolor{red}{\beta_{12}X_1}, \textcolor{red}{\beta_{13}X_1}$
    \item Complex Shift (CS):  $\textcolor{blue}{f(X_2)}$
\end{itemize}

\vspace{0.2cm}
\textsb{Assemble transformation functions:}
\begin{align*}
& \boxed{h(X_i \mid \text{pa}(X_i)) = \text{SI} + \text{LS} + \text{CS}} \\
& h(X_1) = \textcolor{violet}{h_I(X_1)} \\
& h(X_2 \mid X_1) = \textcolor{violet}{h_I(X_2)} + \textcolor{red}{\beta_{12} X_1} \\
& h(X_{3,k} \mid X_1, X_2) = \textcolor{violet}{\vartheta_k} + \textcolor{red}{\beta_{13} X_1} + \textcolor{blue}{f(X_2)} 
\end{align*}

\end{column}

% Right side: Image
\begin{column}{0.35\textwidth}
\begin{figure}
  \centering
  \includegraphics[width=0.65\linewidth]{img/CS.png}
  \caption{$\text{CS}_{X_2}$ on $X_3$}
\end{figure}
\end{column}

\end{columns}

\end{frame}


% \begin{frame}{Experiment 1: TRAM-DAGs}
% \begin{itemize}
%         \item Samples: 20'000 training observations
%         \item Learning rate: 0.005
%         \item Epochs: 400
%         \item Minimizing negative log likelihood (NLL) during training
%         
% \end{itemize}
% \end{frame}


\begin{frame}{TRAM-DAGs: Experiment 1 (simulation)}

% no centering

\textbf{Model fitting:} 20,000 training samples, 400 epochs
{
\centering
  \includegraphics[width=1\linewidth]{img/experiment1/exp1_loss_parameters.png}
}
  


\end{frame}



\begin{frame}{Sampling from the Fitted TRAM-DAG (L1)}

\begin{columns}

% Left column: Sampling explanation
\begin{column}{0.65\textwidth}

\textbf{Nodes $X_i , i \in \{1,\, 2,\, 3\}$:}

\vspace{0.2cm}

\begin{itemize}
    \item Sample latent value: 
    \[
    z_i \sim F_{Z_i} \quad \text{(e.g., \texttt{rlogis()} in R)}
    \]

    \item Determine \(x_i\) such that:

    \begin{itemize}
        \item \textbf{If \(X_i\) is continuous:}
        Solve for \(x_i\) using numerical root-finding:
        \[
        h(x_i \mid \text{pa}(x_i)) - z_i = 0
        \]
        % \[
        % h(x_i \mid \text{pa}(x_i)) - z_i = 0 \text{ for } x_i \text{ (numerical root-finding)}
        % \]
        % 
        \item \textbf{If \(X_i\) is ordinal:}
        find the smallest category $x_i$ such that
        \[
        x_i = \max \left( \{0\} \cup \left\{ x : z_i > h(x \mid \text{pa}(x_i)) \right\} \right) + 1
        \]
        
    \end{itemize}
\end{itemize}

\end{column}

% Right column: Illustration
\begin{column}{0.3\textwidth}
\includegraphics[width=0.9\linewidth]{img/Sampling.png}
\end{column}

\end{columns}

\end{frame}


% 
% 
% \begin{frame}{Sampling from the Fitted TRAM-DAG (interventional)}
% 
% \textbf{Interventional sampling:} \\
% 
% \begin{itemize}
%     \item Do-intervention: \( \textcolor{red}{\text{do}(x_2 = \alpha})\)
%     \item Sample from the interventional-distribution:
% \end{itemize}
% \[
% x_3 = \min \left\{ x : z_3 \le h(x \mid x_1, \textcolor{red}{x_2 = \alpha}) \right\}
% \]
% 
% \centering
% \includegraphics[width=0.5\linewidth]{img/interventional.png}
% 
% 
% \end{frame}



\begin{frame}{TRAM-DAGs: Experiment 1 (simulation)}

\textbf{Sampled observational and interventional distributions:}

  \centering
  \includegraphics[width=0.85\linewidth]{img/experiment1/exp1_observational_distribution.png}
  \includegraphics[width=0.85\linewidth]{img/experiment1/exp1_interventional_distribution.png}

\end{frame}

% 
% 
% \begin{frame}{Experiment 1: TRAM-DAGs (learned shifts)}
% 
%   \centering
%   \includegraphics[width=1\linewidth]{img/experiment1/exp1_LS_CS.png}
% 
% \end{frame}
% 
% 
% 
% \begin{frame}{Experiment 1: TRAM-DAGs (learned intercepts)}
% 
%   \centering
%   \includegraphics[width=1\linewidth]{img/experiment1/exp1_baseline_trafo.png}
% 
% \end{frame}





% \begin{frame}{Experiment 1: TRAM-DAGs (simulation)}
% 
% How to determine a counterfactual value for $X_2$, given some observation?
% 
%   \centering
%   \includegraphics[width=0.95\linewidth]{img/experiment1/counterfactuals.png}
% 
% \end{frame}



\begin{frame}{Experiment 1: TRAM-DAGs (Simulation)}

\vspace{-0.5em}
How to determine a counterfactual value for \(X_2\) using Pearl's 3-step procedure \citep{pearl_book2009}:

\vspace{0.5em}
\begin{columns}

% Left column: Pearl's 3 steps
\begin{column}{0.35\textwidth}
\small

\vspace{0.5em}
\begin{enumerate}
    \item \textbf{Abduction}: Infer \(Z\) from observed data
    \item \textbf{Action}: Modify SCM (e.g., do($X = \alpha$))
    \item \textbf{Prediction}: Infer counterfactual outcome
\end{enumerate}
\end{column}

% Right column: visualization
\begin{column}{0.65\textwidth}
\centering
\includegraphics[width=\linewidth]{img/experiment1/counterfactuals.png}
\end{column}

\end{columns}
\end{frame}



\begin{frame}{Experiment 1: TRAM-DAGs (simulation)}

\textbf{Counterfactuals:} Counterfactual value of $X_2$ under varying $X_1$

  \centering
  \includegraphics[width=0.9\linewidth]{img/experiment1/exp1_counterfactuals.png}

\end{frame}




\begin{frame}{Experiment 1: TRAM-DAGs (simulation)}


\textbf{Discussion:} With TRAM-DAGs we can

\begin{itemize}
    \item estimate the functional form of the edges in the DAG
    \item customize flexibility and interpretability (SI/CI, LS, CS)
    \item sample from the fitted model (observational/interventional)
    \item estimate counterfactuals
\end{itemize}
\end{frame}




\begin{frame}[plain]
\centering
\vspace{0.3\textheight}
{\usebeamercolor[fg]{title} \LARGE \textbf{Individualized Treatment Effects} \\[1ex] \usebeamercolor[fg]{title} \LARGE \textbf{(ITEs)} }
\end{frame}


% 
\begin{frame}{Individualized Treatment Effect (ITE): Motivation}

\textbf{Why ITE?}

\begin{itemize}
  \item RCTs estimate the Average Treatment Effect (ATE)
  \item Individuals may respond differently based on covariates
  \item Important for personalized medicine, targeted marketing, etc.
  \item Heterogeneity mostly driven by treatment-covariate interactions
\end{itemize}

% \vspace{0.5em}
\textbf{Definition:} Difference in potential outcomes \citep{rubin2005}
\[
Y_i(1) - Y_i(0)
\]

\textit{where \( Y_i(1) \): outcome if treated, \( Y_i(0) \): if not treated}

% \vspace{0.5em}
\textbf{Fundamental problem:} We never observe both \( Y_i(1) \) and \( Y_i(0) \) for the same individual \citep{holland1986}.


\end{frame}



% 
% \begin{frame}{Individualized Treatment Effect (ITE): Motivation}
% 
% 
% \textbf{Motivation:}
% 
% \begin{itemize}
%     \item RCT typically estimates Average Treatment Effect (ATE)
%     \item Individuals may respond differently depending on characteristics
%     \item Crucial for decision-making in personalized medicine or targeted marketing
%     \item Heterogeneous treatment effect mainly due to treatment-covariate-interactions
% \end{itemize}
%     
% \textbf{Individual treatment effect:} Difference in potential outcomes
% 
% \[
% Y_i(1) - Y_i(0)
% \]
% 
% , where $Y_i(1)$ is the potential outcome if treated and $Y_i(0)$ if not treated.
% 
% % arrow Fundamental Problem of Causal Inference:} We cannot observe both potential outcomes for the same individual.
% 
% Fundamental problem of causal inference $\rightarrow$ We cannot observe both potential outcomes for the same individual.
% 
% \end{frame}



% \begin{frame}{Individualized Treatment Effect (ITE): Assumptions}
% 
% 
% \textbf{Assumptions for identifiability of causal effects from observed data:}
% 
% \begin{enumerate}
%     \item \textsb{Consistency:} $Y = Y(1)$ if $T = 1$, and $Y = Y(0)$ if $T = 0$ \\
%     Observed outcome equals the potential outcome under the treatment actually received
%     \item \textsb{Ignorability/Unconfoundedness:} $(Y(1), Y(0)) \perp T \mid \mathbf{X}$ \\
%     Treatment assignment is independent of potential outcomes given observed covariates
%     \item \textsb{Overlap/Positivity:} $0 < \text{P}(T = 1 \mid \mathbf{X} = \mathbf{x}) < 1 \quad \text{for all } \mathbf{x}$ \\
%     Every individual has a positive probability of receiving each treatment level
%     \item \textsb{No interference:} The treatment of one individual does not affect the potential outcomes of another individual.
% \end{enumerate}
% 
% \end{frame}

% 
% 
% \begin{frame}{Individualized Treatment Effect (ITE): Estimand}
% 
% \textbf{If assumptions for identifiability are satisfied:}
% 
% \begin{align}
% \text{ITE}(\mathbf{x}_i) &= \mathbb{E}[Y_i(1) - Y_i(0) \mid \mathbf{X} = \mathbf{x}_i] \notag \\[0.5em]
% &= \mathbb{E}[Y_i(1) \mid \mathbf{X} = \mathbf{x}_i] - \mathbb{E}[Y_i(0) \mid \mathbf{X} = \mathbf{x}_i] \notag \\[0.5em]
% &= \mathbb{E}[Y_i(1) \mid T = 1, \mathbf{X} = \mathbf{x}_i]
%   - \mathbb{E}[Y_i(0) \mid T = 0, \mathbf{X} = \mathbf{x}_i] \\
% &\quad \quad \text{(by ignorability)} \notag \\[0.5em] % Added a new line for the comment with indentation
% &= \mathbb{E}[Y_i \mid T = 1, \mathbf{X} = \mathbf{x}_i]
%   - \mathbb{E}[Y_i \mid T = 0, \mathbf{X} = \mathbf{x}_i] \notag \\
% &\quad \quad \text{(by consistency)} \notag % Added a new line for the comment with indentation
% \end{align}
% 
% 
% 
% For a binary outcome:
% 
% \vspace{-0.5cm}
% 
% \begin{equation}
% \text{ITE}(\mathbf{x}_i) = \text{P}(Y_i = 1 \mid T = 1, \mathbf{X} = \mathbf{x}_i) - \text{P}(Y_i = 1 \mid T = 0, \mathbf{X} = \mathbf{x}_i).
% \end{equation}
% 
% \end{frame}
% 




\begin{frame}{From Unobservable to Estimable ITE}
\small
\textbf{Goal:} Estimate the \textit{individualized treatment effect (ITE)} from observed data \citep{hoogland2021}.

\vspace{0.5em}
\begin{align*}
\text{ITE}(\mathbf{x}_i) 
&= \mathbb{E}[Y_i(1) - Y_i(0) \mid \mathbf{X} = \mathbf{x}_i] \\
&= \mathbb{E}[Y_i(1) \mid T=1, \mathbf{X} = \mathbf{x}_i] - \mathbb{E}[Y_i(0) \mid T=0, \mathbf{X} = \mathbf{x}_i] \\
& \quad \textit{\footnotesize (by ignorability/exchangeability: no unmeasured confounding)} \\[0.5em]
&= \mathbb{E}[Y_i \mid T=1, \mathbf{X} = \mathbf{x}_i] - \mathbb{E}[Y_i \mid T=0, \mathbf{X} = \mathbf{x}_i] \\
& \quad \textit{\footnotesize (by consistency: observed = potential outcome, e.g. correct label)}
\end{align*}

\vspace{0.7em}
\textbf{Further assumptions:}
\begin{itemize}
  \item \textbf{Positivity:} every individual could receive either treatment (e.g. no deterministic assignment)
  \item \textbf{No interference:} one person's treatment does not affect another's outcome
\end{itemize}
\end{frame}


% 
% \begin{frame}{Individualized Treatment Effect (ITE): Estimand}
% 
% 
% \textbf{If assumptions for identifiability are satisfied:}
% 
% \begin{align}
% \text{ITE}_i(\mathbf{x}_i) &= \mathbb{E}[Y_i(1) - Y_i(0) \mid \mathbf{X}_i = \mathbf{x}_i] \notag \\[0.5em]
% &= \mathbb{E}[Y_i(1) \mid \mathbf{X}_i = \mathbf{x}_i] - \mathbb{E}[Y_i(0) \mid \mathbf{X}_i = \mathbf{x}_i] \notag \\[0.5em]
% &= \mathbb{E}[Y_i(1) \mid T_i = 1, \mathbf{X}_i = \mathbf{x}_i]
%  - \mathbb{E}[Y_i(0) \mid T_i = 0, \mathbf{X}_i = \mathbf{x}_i] \quad \text{(by ignorability)} \notag \\[0.5em]
% &= \mathbb{E}[Y_i \mid T_i = 1, \mathbf{X}_i = \mathbf{x}_i]
%  - \mathbb{E}[Y_i \mid T_i = 0, \mathbf{X}_i = \mathbf{x}_i] \quad \text{(by consistency)}
% \end{align}
% 
% 
% For a binary outcome:
% 
% \begin{equation}
% \text{ITE}_i(\mathbf{x}_i) = \text{P}(Y_i = 1 \mid T_i = 1, \mathbf{X}_i = \mathbf{x}_i) - \text{P}(Y_i = 1 \mid T_i = 0, \mathbf{X}_i = \mathbf{x}_i).
% \end{equation}
% 
% \end{frame}




\begin{frame}{Individualized Treatment Effect (ITE): Models}

\small
\textbf{How did we estimate the potential outcomes \( \mathbb{E}[Y_i \mid T = t, \mathbf{X} = \mathbf{x}_i] \)?}

\vspace{0.5em}
\begin{itemize}
  \item \textsb{T-learner:} 
    \begin{enumerate}
      \item Fit two separate models on treated and control groups
      \item Predict \( \mathbb{E}[Y_i \mid \mathbf{X} = \mathbf{x}_i] \) from each model
    \end{enumerate}
    \begin{itemize}
      \item Logistic regression / Random forest (with hyperparameter tuning)
    \end{itemize}

  \item \textsb{S-learner:} 
    \begin{enumerate}
      \item Fit one model on all data with treatment as a feature
      \item Predict \( \mathbb{E}[Y_i \mid \text{do}(T = t), \mathbf{X} = \mathbf{x}_i] \) by setting \( T = 0 \) and \( T = 1 \)
    \end{enumerate}
    \begin{itemize}
      \item TRAM-DAGs (flexible, interactions, interventions/counterfactuals)
    \end{itemize}
\end{itemize}

\end{frame}




% \begin{frame}{Individualized Treatment Effect (ITE): Models}
% 
% \small
% \textbf{How did we estimate the potential outcomes \( \mathbb{E}[Y_i \mid T = t, \mathbf{X} = \mathbf{x}_i] \)?}
% 
% \vspace{0.5em}
% \begin{itemize}
%   \item \textsb{T-learner:} 1) fit two separate models on treated and control groups 2) with each model predict\( \mathbb{E}[Y_i \mid \mathbf{X} = \mathbf{x}_i] \)
%     \begin{itemize}
%       \item Logistic regression / Random forest (with hyperparameter tuning)
%     \end{itemize}
%   \item \textsb{S-learner:} 1) fit one model on all data with treatment as a feature 2) predict \( \mathbb{E}[Y_i \mid do(T = t), \mathbf{X} = \mathbf{x}_i] \)
%     \begin{itemize}
%       \item TRAM-DAGs (flexible, deep architecture with treatment-aware design)
%     \end{itemize}
% \end{itemize}
% 
% \end{frame}




\begin{frame}{Experiment 2: ITE on International Stroke Trial (IST)}


\textbf{Background/Motivation:} \citet{chen2025} showed that results of models used for ITE estimation did not generalize to the test set.


\textsb{International Stroke Trial (IST):}

\begin{itemize}
    \item Large RCT on stroke patients (19,435 patients, 21 baseline covariates)
    \item Evaluated the effects of aspirin on death or dependence at 6 months
    \item Binary treatment and outcome
\end{itemize}



\textsb{Research question:} Do we reach similar conclusion as \citet{chen2025} when estimating ITEs with T-learners (logistic regression, tuned random forest) and an S-learner (TRAM-DAGs) on the IST dataset.

\end{frame}



% 
% \begin{frame}{Experiment 2: ITE on International Stroke Trial (IST): Results}
% 
% Results with T-learner logistic regression (glm):
% 
% % Below: image
% \includegraphics[width=\textwidth]{img/Experiment2/glm_tlearner_density_ITE_ATE.png}
% 
% \end{frame}
% 


\begin{frame}{Experiment 2: ITE on International Stroke Trial (IST)}

\textbf{Results:} with T-learner tuned random forest using the \texttt{comets} package \citep{comets}:

% Below: image
\includegraphics[width=\textwidth]{img/Experiment2/IST_tuned_rf_tlearner_density_ITE_ATE.png}

\end{frame}



\begin{frame}{Experiment 2: ITE on International Stroke Trial (IST)}

\textbf{Discussion:}

\begin{itemize}
    \item We obtained similar results as \citet{chen2025}
    \item Some models suggest moderate treatment effect heterogeneity, but the ITEs do not generalize to the test set (no effect)
    \item We do not certainly know why, since ground truth is unknown
\end{itemize}

\end{frame}



% 
% \begin{frame}{Causal ML Models for ITE estimation}
% 
% Meta learners (T-learner, S-learner etc.)
% 
% 
% Tram dags
% 
% \end{frame}
% 
% 
% 
% 
% 
% \begin{frame}{IST Stroke trial}
% 
% 
% Explain the trial
% 
% \end{frame}
% 
% 
% 
% 
% 
% 
% \begin{frame}{IST Stroke trial: Results with GLM}
% 
% Show results of tlearner GLM
% 
% \end{frame}
% 
% 
% \begin{frame}{IST Stroke trial: Results with Random Forest}
% 
% 
% 
% 
% 
% 
% 
% 
% \end{frame}
% 
% 
% \begin{frame}{IST Stroke trial: Results with tram dag}
% 
% Show results of tram dag
% 
% \end{frame}
% 
% 
% 
% \begin{frame}{Simulation: When do problems occur?}
% 
% explain setup with dag and effect sizes and interactions that affect outcome
% 
% \end{frame}
% 
% 



\begin{frame}{Experiment 3:  ITE model robustness in RCTs (simulation)}

\textbf{Motivation:} ITE estimation did not generalize to the test data on the real-world RCT of the International Stroke Trial (IST). We want to know why!


\textsb{Research question:} What factors contribute to the failure of ITE estimation in causal models? %, and under which conditions can reliable estimates be obtained?

\textsb{Setup:}
\begin{itemize}
    \item Simulate different RCT scenarios to understand when ITE estimation fails
    \item Apply simple model (logistic regression; matching DGP) and non-parametric model (tuned random forest)
\end{itemize}


\end{frame}




\begin{frame}{Simulation Case 1: Fully Observed}

\begin{columns}

% Left column: Text
\begin{column}{0.52\textwidth}

\vspace{-0.5em}
\textbf{Setup:}
\begin{itemize}\setlength\itemsep{0.4em}
  \item $n = 20{,}000$
  \item $T \sim \text{Bernoulli}(0.5)$
  \item $\mathbf{X} = (X_1, \dots, X_5)^\top \sim \mathcal{N}(\mathbf{0}, \Sigma)$\\
  \item $\mathbf{X_{TX}} = (X_1, X_2)^\top$ \textcolor{red}{interaction}
\end{itemize}


\end{column}

% Right column: DAG image
\begin{column}{0.42\textwidth}
    \includegraphics[width=\textwidth]{img/simulation_observed.png}
\end{column}

\end{columns}


\vspace{0.3em}
\textbf{Outcome model:}
\[
\mathbb{P}(Y = 1 \mid \mathbf{X}, T) = \text{logit}^{-1} \left(
\beta_0 + \beta_T T + \boldsymbol{\beta}_X^\top \mathbf{X}
+ \textcolor{red}{T \cdot \boldsymbol{\beta}_{TX}^\top \mathbf{X_{TX}}}
\right)
\]


\end{frame}





\begin{frame}{Simulation Case 1: Fully Observed}

Results with T-learner logistic regression (glm):
\vfill

% Below: image
\includegraphics[width=\textwidth]{img/fully_observed_glm_tlearner.png}

\end{frame}


\begin{frame}{Simulation Case 1: Fully Observed}

Results with T-learner tuned random forest (\texttt{comets} package):

\vfill
% Below: image
\includegraphics[width=\textwidth]{img/observed_tuned_rf.png}

\end{frame}



\begin{frame}{Simulation Case 1: Fully Observed}

Results with (untuned) T-learner random forest using the \texttt{randomForest} package \citep{breiman2001}:

\vfill
% Below: image
\includegraphics[width=\textwidth]{img/fully_observed_rf_tlearner.png}

\end{frame}






\begin{frame}{Simulation Case 2: Unobserved Interaction}

\begin{columns}

% Left column: Text
\begin{column}{0.52\textwidth}

\vspace{-0.5em}
\textbf{Setup:}
\begin{itemize}\setlength\itemsep{0.4em}
  \item $n = 20{,}000$
  \item $T \sim \text{Bernoulli}(0.5)$
  \item $\mathbf{X} = (X_1, \dots, X_5)^\top \sim \mathcal{N}(\mathbf{0}, \Sigma)$\\
  \item $\mathbf{X_{TX}} = (X_1, X_2)^\top$ \textcolor{red}{interaction}
\end{itemize}


\end{column}

% Right column: DAG image
\begin{column}{0.42\textwidth}
    \includegraphics[width=\textwidth]{img/simulation_unobserved.png}
\end{column}

\end{columns}


\vspace{0.3em}
\textbf{Outcome model:}
\[
\mathbb{P}(Y = 1 \mid \mathbf{X}, T) = \text{logit}^{-1} \left(
\beta_0 + \beta_T T + \boldsymbol{\beta}_X^\top \mathbf{X}
+ \textcolor{red}{T \cdot \boldsymbol{\beta}_{TX}^\top \mathbf{X_{TX}}}
\right)
\]

% in this scenario X1 is unobserved
\textbf{Note:} Same DGP, but $X_1$ is not observed!

\end{frame}




\begin{frame}{Simulation Case 2: Unobserved Interaction}

Results with T-learner logistic regression (glm):
\vfill
% Below: image
\includegraphics[width=\textwidth]{img/unobserved_interaction_glm_tlearner.png}

\end{frame}

\begin{frame}{Simulation Case 2: Unobserved Interaction}

Results with T-learner tuned random forest (\texttt{comets} package):
\vfill
% Below: image
\includegraphics[width=\textwidth]{img/unobserved_tuned_rf.png}

\end{frame}





\begin{frame}{Simulation Case 3: Fully Observed, Small Effects}

\begin{columns}

% Left column: Text
\begin{column}{0.52\textwidth}

\vspace{-0.5em}
\textbf{Setup:}
\begin{itemize}\setlength\itemsep{0.4em}
  \item $n = 20{,}000$
  \item $T \sim \text{Bernoulli}(0.5)$
  \item $\mathbf{X} = (X_1, \dots, X_5)^\top \sim \mathcal{N}(\mathbf{0}, \Sigma)$\\
  \item $\mathbf{X_{TX}} = (X_1, X_2)^\top$ \textcolor{red}{interaction}
\end{itemize}


\end{column}

% Right column: DAG image
\begin{column}{0.42\textwidth}
    \includegraphics[width=\textwidth]{img/simulation_small_effects.png}
\end{column}

\end{columns}


\vspace{0.3em}
\textbf{Outcome model:}
\[
\mathbb{P}(Y = 1 \mid \mathbf{X}, T) = \text{logit}^{-1} \left(
\beta_0 + \beta_T T + \boldsymbol{\beta}_X^\top \mathbf{X}
+ \textcolor{red}{T \cdot \boldsymbol{\beta}_{TX}^\top \mathbf{X_{TX}}}
\right)
\]

\textbf{Note:} Same DGP, but weak treatment effects!


\end{frame}





\begin{frame}{Simulation Case 3: Fully Observed, Small Effects}

Results with T-learner logistic regression (glm):
\vfill
% Below: image
\includegraphics[width=\textwidth]{img/small_interaction_glm_tlearner.png}

\end{frame}


\begin{frame}{Simulation Case 3: Fully Observed, Small Effects}

Results with T-learner tuned random forest (\texttt{comets} package):
\vfill
% Below: image
\includegraphics[width=\textwidth]{img/small_interaction_tuned_rf_tlearner.png}

\end{frame}



\begin{frame}{Experiment 3:  ITE model robustness in RCTs (simulation)}

\small

\textbf{Key Insights:}
\begin{itemize}
  \item \textsb{Calibration} and tuning of models are crucial for reliable ITE estimation
  \item Ignorability alone may not guarantee unbiased ITEs if important \textsb{effect modifiers are unobserved}
  \item \textsb{Low true heterogeneity} may be mistaken for model failure
\end{itemize}

These factors may explain the limited ITE performance in the IST dataset.

\end{frame}


% 
% 
% \begin{frame}{Experiment 3:  ITE model robustness in RCTs (simulation)}
% 
% \textbf{Discussion:} 
% 
% \begin{itemize}
%     \item When a high predicted treatment effect (ITE) corresponds to a high observed effect in the train set (strong discrimination), but not in the test set, it might be due to \textbf{unobserved interaction variables} or \textbf{weak treatment effects}.
%     \item This is more likely to occur with complex models, as they tend to overfit when the interaction is not observed.
%     % as they tend to predict a wider range of ITEs than simpler models
% \end{itemize}
% 
% 
% \end{frame}




% 
% \begin{frame}{TRAM-DAGs for ITE Estimation}
% 
% \begin{columns}
% 
% % Left side: Text (approx. 3/4 of the slide)
% \begin{column}{0.7\textwidth}
% 
% \textbf{Paper \textit{"Interpretable Neural Causal Models with TRAM-DAGs"} \citep{sick2025}:}
% \begin{itemize}
%     \item Framework to model causal relationships
%     \item Based on transformation models
%     \item Rely on (deep) neural networks
%     \item Compromise between interpretability and flexibility
% \end{itemize}
% 
% \textbf{Our Claim:} We can use TRAM-DAGs for ITE estimation, as long as the DAG is known and fully observed!
% 
% \end{column}
% 
% % Right side: Image (approx. 1/4 of the slide)
% \begin{column}{0.3\textwidth}
% \includegraphics[width=\textwidth]{img/TRAM_DAG_Background.png}
% \end{column}
% 
% \end{columns}
% 
% \end{frame}
% 
% 


% 
% \begin{frame}{TRAM-DAGs: Structural Equations}
% 
% 
% TRAM-DAGs estimate the structural equations with transformation functions $h_i$:
% 
% \begin{columns}
% 
% % Left side: Text
% \begin{column}{0.5\textwidth}
% 
% $Z_i = h_i(X_i \mid \text{pa}(X_i))$ \\
% $X_i = h_i^{-1}(Z_i, \text{pa}(X_i)) = f_i(Z_i, \text{pa}(X_i))$ \\
% 
% %empty line
% \vspace{1.5em}
% 
% \begin{itemize}
%     \item $\text{pa}(X_i)$: causal parents of $X_i$
%     \item $Z_i$: noise distribution (e.g. standard logistic)
% \end{itemize}
% 
% \end{column}
% 
% % Right side: Image
% \begin{column}{0.5\textwidth}
% \includegraphics[width=\textwidth]{img/trafo_xi.png}
% \end{column}
% \end{columns}
% 
% 
% \end{frame}





\begin{frame}{Experiment 4: ITE estimation with TRAM-DAGs}

\centering
\includegraphics[width=0.8\textwidth]{img/dag_ITE_observational.png}

% \normalsize

% \vspace{1em} % optional spacing
\raggedright % <--- Ends centering and left-aligns following text

\small
\textbf{DGP:}\vspace{-0.5em}
\begin{itemize}
    \item $X_1, X_2, X_3 \sim \mathcal{N}(\mathbf{0}, \Sigma)$
    \item $X_4$ (treatment) depends probabilistically on $X_1$ and $X_2$ via a logistic model
    \item $X_5 = h_5^{-1}(Z_5 - 0.8 \, X_4 )$ \hspace{1em} $\rightarrow$ (depends on treatment)
    \item $X_6 = h_6^{-1}(Z_6 + 0.5 \, X_5)$ \hspace{1em} $\rightarrow$ (depends on treatment through $X_5$)
    \item $Y = h_7^{-1}(Z_7 - \beta_1 X_1 - \beta_2 X_2 - \beta_3 X_3 - \beta_4 X_4 - \beta_5 X_5 - \beta_6 X_6 - \textcolor{red}{X_4 \cdot (\beta_{2,Tr} X_2 + \beta_{3,Tr} X_3)})$
\end{itemize}

\end{frame}






% \begin{frame}{TRAM-DAGs: Estimate Potential Outcomes}
% 
% If we observe a $X5$ under $Tr=0$, we can determine the counterfactual $X5$ under $Tr=1$ with the observed latent value $z_j$:
% 
% \centering
% \includegraphics[width=0.7\textwidth]{img/counterfactual_X5.png}
% 
% \end{frame}
% 
% 



\begin{frame}{Experiment 4: ITE estimation with TRAM-DAGs}

We define the ITE as the difference in medians of potential outcomes:

\[
\text{ITE} = \operatorname{median}(Y \mid \text{do}(T = 1), \mathbf{X}) - \operatorname{median}(Y \mid \text{do}(T = 0), \mathbf{X})
\]

\centering

\includegraphics[width=0.7\textwidth]{img/potential_outcomes_y.png}



\end{frame}





\begin{frame}{Experiment 4: ITE estimation with TRAM-DAGs}


Resulting ITEs from the DGP in terms of difference in medians of potential outcomes: \vspace{-0.5em}

\[
\text{ITE} = \operatorname{median}(Y \mid \text{do}(T = 1), \mathbf{X}) - \operatorname{median}(Y \mid \text{do}(T = 0), \mathbf{X})
\]

\vspace{-0.5em}

\centering
\includegraphics[width=0.7\textwidth]{img/observ_scenario1_ite_distribution_dgp.png}

\end{frame}



% \begin{frame}{Experiment 4: ITE estimation with TRAM-DAGs}
% 
% Estimate ITEs with TRAM-DAGs (S-learner) from observational data including mediators $X_5$ and $X_6$:
% 
% \begin{enumerate}
%     \item Estimate each $h_i(X_i \mid \text{pa}(X_i))$ fully flexible (deep-NN / complex intercept) on the train set
%     \item Take the train set or the test set
%     \item $z_i = h(x_i \mid \text{pa}(x_i))$ gives us the (observed) latent variable for each $x_i$
%     \item Determine counterfactuals for $x_5$ and $x_6$ with the (observed) latent variables $z_i$
%     % \item Determine medians of potential outcome distributions $Y(1)$ and $Y(0)$
%     \item $\text{ITE} = \text{median}(Y \mid  \text{do}(T = 1), \mathbf{X_{tx}}) - \text{median}(Y \mid \text{do}(T = 0), \mathbf{X_{ct}})$
% \end{enumerate}
% 
% \end{frame}



\begin{frame}{Experiment 4: ITE Estimation with TRAM-DAGs}

Estimate ITEs with TRAM-DAGs (S-learner approach) from observed data:

\begin{enumerate}
    \item Fit the TRAM-DAG on the training set (fully flexible -- CI --  to allow for interactions)
    \item Compute potential outcomes as $\text{median}(Y \mid \text{do}(T = t), \mathbf{X}_t)$ for $t \in \{0, 1\}$
    \item $\text{ITE} = \text{median}(Y \mid \text{do}(T = 1), \mathbf{X}_1) - \text{median}(Y \mid \text{do}(T = 0), \mathbf{X}_0)$
\end{enumerate}

\end{frame}




% \begin{frame}{TRAM-DAGs: Example for ITE estimation (Results)}
\begin{frame}{ITE estimation with TRAM-DAGs (Results)}
\centering

\begin{minipage}{0.34\textwidth}
    \centering
    \includegraphics[width=\textwidth]{img/Experiment4/observ_scenario1_ITE_densities_train_test.png}
\end{minipage}
\hspace{0.05\textwidth} % Smaller fixed horizontal spacing
\begin{minipage}{0.34\textwidth}
    \centering
    \includegraphics[width=\textwidth]{img/Experiment4/observ_scenario1_ITE_scatter_train_test.png}
\end{minipage}
\end{frame}



% ITE-ATE plot biased because confounded? (observational)

% \begin{frame}{TRAM-DAGs: Example for ITE estimation (Results)}
% 
% 
% \centering
% \includegraphics[width=0.9\textwidth]{img/observedITE_ATE_base.png}
% 
% 
% 
% \end{frame}


% 
% \begin{frame}{Conclusion: Key Findings \& Outlook}
% 
% \textbf{TRAM-DAGs:}
% \begin{itemize}\setlength\itemsep{4pt}
%   \item Flexible and customizable; recovers known causal structure
%   \item Captures interactions between variables
% \end{itemize}
% 
% \textbf{ITE Estimation:}
% \begin{itemize}\setlength\itemsep{4pt}
%   \item Calibration is crucial
%   \item Sensitive to missing effect modifiers or weak heterogeneity
%   \item TRAM-DAGs yield unbiased ITEs when DAG is correct and heterogeneity exists
% \end{itemize}
% 
% \textbf{Limitations:}
% Simulations simplify reality; modeling assumptions affect interpretability (e.g., scale of effects)
% 
% \textbf{Recommendations:}
% Apply TRAM-DAGs to real-world data; study ITE estimation under unobserved effect modifiers
% 
% \end{frame}





\begin{frame}{Key Findings}

% check findings in thesis

\textbf{Findings: TRAM-DAGs}

\begin{itemize}
\item Customizable; accurately recovers causal relationships in known DAG; allows sampling of L1-L3
% \item Customizable in terms of flexibility/interpretability
\item Can model interactions between variables
\end{itemize}

\textbf{Findings: Individualized treatment effects (ITE)}

\begin{itemize}
\item Calibration is important for ITE prediction
% \item ITE estimation on International Stroke Trial failed
\item Missing effect modifiers (or weak heterogeneity) are problematic
\item TRAM-DAGs yield unbiased ITEs when DAG is correct and heterogeneity exists
\end{itemize}


\end{frame}


% 
% \begin{frame}{Outlook}
% 
% % check findings in thesis
% 
% 
% 
% \textbf{Limitations:} TRAM-DAGs: Simulations may not represent real-world complexity; to ensure interpretable coefficients are valid, the correct model must be fitted; requires considerable training time. ITE: for continuous outcome we used QTE at the median
% 
% 
% \textbf{Recommendations:} Apply TRAM-DAGs on real-world data; ITE estimation under unobserved effect modifiers
% 
% \end{frame}

\begin{frame}{Outlook}

% \small
\textbf{Limitations}
\begin{itemize}
  \item Simulations may not reflect real-world complexity
  \item TRAM-DAGs are computationally expensive (long training time)
  \item TRAM-DAGs require correct model specification for interpretability
  \item ITE estimation for continuous outcomes used medians of potential outcomes instead of expected values
\end{itemize}


\vspace{0.5em}
\textbf{Recommendations}
\begin{itemize}
  \item Apply TRAM-DAGs to real-world datasets, including semi-structured data
  \item Investigate ITE estimation under unobserved effect modifiers
\end{itemize}

\end{frame}

% 
% \begin{frame}{TRAM-DAGs: Example for ITE estimation (Results)}
% 
% 
% 
% % Comparison of ATE in RCT with $\E(\text{ITE}_{predicted})$
% 
% 
% \textbf{ATE TRAM-DAG:} estimated as $\operatorname{mean}(\text{ITE}_{predicted})$:
% 
% 
% -0.619 (-0.627 to -0.617)
% 
% \vspace{1em}
% 
% \textbf{ATE from RCT (randomized:)} estimated as \\ 
% observed $\operatorname{median}(Y \mid T = 1)$ - $\operatorname{median}(Y \mid T = 0)$:
% 
% -0.637 (-0.662 to -0.610)
% 
% 
% \vspace{1em}
% 
% \begin{itemize}
%     \item confidence intervals obtained by bootstrapping
% \end{itemize}
% 
% 
% \end{frame}


\begin{frame}[allowframebreaks, noframenumbering]{References}
  \small
  \bibliographystyle{apalike}
  \bibliography{C:/Users/kraeh/OneDrive/Dokumente/Desktop/UZH_Biostatistik/Masterarbeit/MA_Mike/presentation_report/literature/bibSTA490}
\end{frame}



\begin{frame}{Heterogeneity}

Heterogeneity despite no interaction effects in logistic model \citep{hoogland2021}.

\centering
\includegraphics[width=0.7\textwidth]{img/hoogland.jpg}



\end{frame}

% 
% 
% \begin{frame}{References}
%   \small
%   \bibliographystyle{apalike}
% \bibliography{C:/Users/kraeh/OneDrive/Dokumente/Desktop/UZH_Biostatistik/Masterarbeit/MA_Mike/presentation_report/literature/bibSTA490}
% \end{frame}

\end{document}